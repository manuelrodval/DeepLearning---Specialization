{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Course 1 - Neural Networks and Deep Learning\n",
    "## Logistic reggression as a Neural Network\n",
    "### Binary classification\n",
    "Logistic reggression is an algorithm for binary classification, where the output goes from 0 to 1 for the probability of a certain class.<br>\n",
    "For image classification we are going to unroll the RBG pixels in to a single vector with $n$ features that represent each pixel value. For e.g. in a 64x64 image we are going to have a 64x64x3 (12,288) feature vector.\n",
    "#### Notation\n",
    "- $(x_i,y_i)$ - Single value where $x \\in {\\Bbb R}^{n_x} , y \\in \\{0,1\\}$ \n",
    "- $m$ - Number of trining examples; $\\{(x^{(1)},y^{(1)}),(x^{(2)},y^{(2)}),...,(x^{(m)},y^{(m)})\\}$\n",
    "- $m_{train}$ - Number of training examples\n",
    "- $m_{test}$ - Number of test examples\n",
    "- $X=\\begin{bmatrix}| & | & ... & | \\\\ x^{(1)} & x^{(2)} & ... & x^{(m)} \\\\ | & | & ... & | \\end{bmatrix}$ - $m$ number of training examples and $n_x$ number of features.\n",
    "- $Y = \\begin{bmatrix} y^{(1)} & y^{(2)} & ... & y^{(m)} \\end{bmatrix}$ - Target vector.\n",
    "\n",
    "### Logistic Regression\n",
    "Given $x$ we want $\\hat{y} = P(y=1|x)$, the parameters of the logistic reggresion will be $w \\in {\\Bbb R}^{n_x}$ and $b\\in{\\Bbb R}$.<br>\n",
    "With this parameters we'll use the sigmoid function:\n",
    "- $G(z) = \\cfrac{1}{1+e^{-z}}$\n",
    "<br>\n",
    "- If $z$ is large then $G \\approx 1$, if $z$ is small then $ G\\approx0$\n",
    "- $b$ corresponds to the intercept and $w$ is the vector parameter.\n",
    "\n",
    "So in general, given $\\{(x^{(1)},y^{(1)}),...,(x^{(m)},y^{(m)})\\}$ the logistic regression model to estimate $\\hat{y}^{(i)}\\approx y^{(i)}$ is:\n",
    "\n",
    "- $\\hat{y} = \\sigma(w^Tx + b)$, where $\\sigma(z) = \\cfrac{1}{1+e^{-z}}$\n",
    "\n",
    "### Logistic regression cost function\n",
    "One thing that we can do is to define the loss function as: $\\ell(\\hat{y},y) = \\cfrac{1}{2}*(\\hat{y}-y)^2$, but with this, the optimization problem becomes non convex with multiple local optima so gradient descent will not work.<br>\n",
    "For logistic regression we'll use the following loss function for a single record that will generate a convex optimization problem:\n",
    "- $\\ell(\\hat{y},y) = -(y\\log\\hat{y}+(1-y)\\log(1-\\hat{y})$\n",
    "\n",
    "    - If $y=1 : \\ell(\\hat{y},y) = -\\log\\hat{y}$, we want $\\log (\\hat{y})$ small, want $\\hat{y}$ large.<br>\n",
    "<img src='img/img1.jpg' style=\"width:200px; height:150px\"/>\n",
    "    - If $y=0 : \\ell(\\hat{y},y) = -\\log(1-\\hat{y})$, we want $\\log (1-\\hat{y})$ small, want $\\hat{y}$ small.<br>\n",
    "<img src='img/img2.jpg' style=\"width:200px; height:150px\"/><br><br>\n",
    "\n",
    "For the entire dataset the **Cost function** is as following:\n",
    "- $J(w,b) = = \\cfrac{1}{m} \\sum_{i=1}^{m} \\ell(\\hat{y}^{(i)},y^{(i)}) = -\\cfrac{1}{m} \\sum_{i=1}^{m}[y^{(i)}\\log \\hat{y}^{(i)} + (1-y^{(i)}) \\log (1-\\hat{y}^{(i)})]$\n",
    "\n",
    "### Gradient Descent\n",
    "To minimize $J(w,b)$ we can use the gradient descent algorithm that works as following:<br><br>\n",
    "<img src='img/img3.jpg' style=\"width:300px; height:200px\"/><br>\n",
    "- Repeat {<br>\n",
    "$dw = \\cfrac{\\partial J(w,b)}{\\partial w}$<br>\n",
    "$db = \\cfrac{\\partial J(w,b)}{\\partial b}$<br>\n",
    "$w = w - dw$<br>\n",
    "$b = b - db$   }<br>\n",
    "\n",
    "To perform partial derivatives we have to use the chain rule for derivatives, that means that for calculating $\\cfrac{\\partial J(w,b)}{\\partial J(w)}$, we have to calculate the intermediate derivatives of the logisitic regression model and multiply them. Here are the solved partial derivatives in a vectorized implementation.\n",
    "\n",
    "- $\\cfrac{\\partial J(w,b)}{\\partial w} = \\cfrac{1}{m} X(A-Y)^{T}$\n",
    "- $\\cfrac{\\partial J(w,b)}{\\partial b} = \\cfrac{1}{m} \\sum_{i=1}^{m}(a^{(i)} - y^{(i)})$\n",
    "\n",
    "### Vectorization in Python\n",
    "Here is a demonstration of the performance of vectorized algorithms vs for loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For version:  0.0010008811950683594 ms 238.05301907559655\n",
      "Vectorized version:  0.0010006427764892578 ms 238.05301907559658\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "rands = np.random.RandomState(42)\n",
    "a = rands.rand(1000)\n",
    "rands = np.random.RandomState(69)\n",
    "b = rands.rand(1000)\n",
    "# For version\n",
    "c=0\n",
    "tic = time.time()\n",
    "for i in range(1000):\n",
    "    c+=a[i]*b[i]\n",
    "toc = time.time()\n",
    "print('For version: ',toc-tic,'ms', c)\n",
    "# Vectorized version\n",
    "tic = time.time()\n",
    "c = np.dot(a,b)\n",
    "toc = time.time()\n",
    "print('Vectorized version: ',toc-tic,'ms', c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Broadcasting in python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 50.     0.     4.4   86.8 ]\n",
      " [  1.2  104.    52.     8.9 ]\n",
      " [  1.8  135.     0.99   0.9 ]] \n",
      "\n",
      "[ 53.   239.    57.39  96.6 ] \n",
      "\n",
      "[[94.33962264  0.          7.66684091 89.85507246]\n",
      " [ 2.26415094 43.51464435 90.60811988  9.21325052]\n",
      " [ 3.39622642 56.48535565  1.72503921  0.93167702]]\n"
     ]
    }
   ],
   "source": [
    "# Broadcasting example for a (3,4) matrix division with a (1,4) matrix;\n",
    "A = np.array([[50,0,4.4,86.8],\n",
    "              [1.2,104,52,8.9],\n",
    "              [1.8,135,0.99,0.9]])\n",
    "print(A,'\\n')\n",
    "cal = A.sum(axis=0)\n",
    "print(cal,'\\n')\n",
    "pntg = A*100/cal\n",
    "print(pntg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.08503257 -0.85276594  0.90611041 -2.13006938]\n",
      " [-0.76890618  0.13393535 -2.23901305 -1.74981659]\n",
      " [-2.13324261 -1.29093937  0.50672521  0.06125876]] \n",
      "\n",
      "[[-2.08503257 -0.85276594  0.90611041 -2.13006938]\n",
      " [-0.76890618  0.13393535 -2.23901305 -1.74981659]\n",
      " [-2.13324261 -1.29093937  0.50672521  0.06125876]]\n"
     ]
    }
   ],
   "source": [
    "# Example of transposing and broadcasting;\n",
    "a = np.random.randn(3,4)\n",
    "b = np.random.randn(4,1)\n",
    "c = np.zeros((3,4))\n",
    "for i in range(3):\n",
    "    for j in range(4):\n",
    "        c[i][j] = a[i][j] + b[j]\n",
    "print(c,'\\n')\n",
    "print(a + b.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shallow Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Networks Overview\n",
    "Like in logistic regression, neural networks are a chain of activation functions (e.g. sigmoid function) that forward propagates to calculate the global cost function and then bakcward propagates to calculate new parameters.\n",
    "- Logistic regression model.<br>\n",
    "<img src='img/img4.jpg' style=\"width:300px; height:200px\"/><br>\n",
    "- Neural network model.<br>\n",
    "<img src='img/img5.jpg' style=\"width:600px; height:200px\"/><br>\n",
    "\n",
    "### Neural Network Representation.\n",
    "This is an example of a 2 layer Neural Network where: $a^{[l]\\leftarrow \\text{layer}}_{i\\leftarrow \\text{node in layer}}$. <br>\n",
    "<img src='img/img6.jpg' style=\"width:500px; height:370px\"/><br>\n",
    "\n",
    "### Computing a Neural Network's Output\n",
    "- Calculation steps for logistic regression as a Neural Network.<br>\n",
    "<img src='img/img7.jpg' style=\"width:250px; height:170px\"/><br>\n",
    "- Calculation steps for a single hidden layer Neural Network.<br>\n",
    "<img src='img/img8.jpg' style=\"width:550px; height:170px\"/><br>\n",
    "    - Vectorized notation:<br><br>\n",
    "    $z^{[1]} = \\begin{bmatrix} - & w_{1}^{[1]T} & -  \\\\ - & w_{2}^{[1]T} & - \\\\ - & w_{3}^{[1]T} & - \\\\ - & w_{4}^{[1]T} & - \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\end{bmatrix} + \\begin{bmatrix} b_{1}^{[1]} \\\\ b_{2}^{[1]} \\\\ b_{3}^{[1]} \\\\ b_{4}^{[1]}\\end{bmatrix} = \\begin{bmatrix} w_{1}^{[1]T}x + b_{1}^{[1]} \\\\  w_{2}^{[1]T}x + b_{2}^{[1]} \\\\  w_{3}^{[1]T}x +b_{3}^{[1]} \\\\ w_{4}^{[1]T}x + b_{4}^{[1]} \\end{bmatrix} $ <br><br>\n",
    "    $a^{[1]} = \\sigma (z^{[1]})$<br>\n",
    "    $z^{[2]} = W^{[2]}a^{[1]} + b^{[2]}$<br>\n",
    "    $a^{[2]} = \\sigma (z^{[2]})$\n",
    "    \n",
    "### Vectorizing across multiple examples.\n",
    "To calculate the $A^{[1]}$ and $A^{[2]}$ with a for loop, do:<br>\n",
    "- For $i = 1$ to $m$:<br>\n",
    "$z^{[1](i)} = W^{[1]}x^{(i)} + b^{[1]}$<br>\n",
    "$a^{[1](i)} = \\sigma (z^{[1](i)})$<br>\n",
    "$z^{[2](i)} = W^{[2]}a^{[1](i)} + b^{[2]}$<br>\n",
    "$a^{[2](i)} = \\sigma (z^{[2](i)})$\n",
    "\n",
    "### Explanation for a Vectorized Implementation\n",
    "To implement forward propagation across multiple examples we can implement the following:<br><br>\n",
    "$Z^{[1]} = \\begin{bmatrix} - & w_{1}^{[1]} & -  \\\\ - & w_{2}^{[1]} & - \\\\ - & ... & - \\\\ - & w_{m}^{[1]} & - \\end{bmatrix} \\begin{bmatrix} | & | & | & | & | \\\\ x^{(1)} & x^{(2)} & x^{(3)} & ... & x^{(m)} \\\\ | & | & | & | & | \\end{bmatrix} + \\begin{bmatrix} b^{[1]}_{1} \\\\ b^{[1]}_{2} \\\\ b^{[1]}_{3} \\\\ ... \\\\ b^{[1]}_{m} \\end{bmatrix}$<br>\n",
    "$Z^{[1]} = \\begin{bmatrix} | & | & | & | & | \\\\ z^{[1](1)} & z^{[1](2)} & z^{[1](3)} & ... & z^{[1](m)} \\\\ | & | & | & | & | \\end{bmatrix}$<br><br>\n",
    "With this, the final vetorized implementation looks like this:<br><br>\n",
    "$Z^{[1]} = W^{[1]}X + b^{[1]}$; but $X = A^{[0]}$<br><br>\n",
    "So, the complete vectorized implementation over the proposed neural network looks like this:<br><br>\n",
    "$Z^{[1]} = W^{[1]}A^{[0]} + b^{[1]}$<br>\n",
    "$A^{[1]} = \\sigma (Z^{[1]})$<br>\n",
    "$Z^{[2]} = W^{[2]}A^{[1]} + b^{[2]}$<br>\n",
    "$A^{[2]} = \\sigma (Z^{[2]})$; $\\leftarrow (\\hat{y})$\n",
    "\n",
    "### Activation functions and their derivatives\n",
    "- Sigmoid function $\\rightarrow \\sigma(z) = \\cfrac{1}{1+\\exp^{-z}} \\rightarrow$ derivative: $\\rightarrow \\cfrac{1}{1+\\exp^{-z}}\\left( 1-\\cfrac{1}{1+\\exp^{-z}}\\right)$<br>\n",
    "<img src='img/img9.jpg' style=\"width:250px; height:150px\"/><br>\n",
    "- Hiperbolic tangent function $\\rightarrow tanh(z) = \\cfrac{\\exp^{z}-\\exp^{-z}}{\\exp^{z}+\\exp^{-z}}\\rightarrow$ derivative: $\\rightarrow 1 - (tanh(z))^{2}$<br>\n",
    "<img src='img/img10.jpg' style=\"width:250px; height:150px\"/><br>\n",
    "- Rectified linear unit (ReLU) $\\rightarrow max(0,z) \\rightarrow$ derivative: $\\rightarrow \\big\\{0 \\text{ if } z<0 ; 1 \\text{ if } z>0$<br>\n",
    "<img src='img/img11.jpg' style=\"width:250px; height:150px\"/><br>\n",
    "- Leaking ReLU $\\rightarrow max(0.1*z,z)\\rightarrow$ derivative: $\\rightarrow \\big\\{0.1 \\text{ if } z<0 ; 1 \\text{ if } z>0$<br>\n",
    "<img src='img/img12.jpg' style=\"width:250px; height:150px\"/><br>\n",
    "\n",
    "#### Why do we need to use non-linear activation functions in the hidden layers?\n",
    "If you use a linear activation function in the hidden layers, the following will happen:\n",
    "- if $g(z) = z$\n",
    "$a^{[1]} = z^{[1]} = w^{[1]}x + b^{[1]}$<br>\n",
    "$a^{[2]} = w^{[2]}(w^{[1]}x + b^{[1]}) + b^{[2]}$<br>\n",
    "$a^{[2]} = (w^{[2]}w^{[1]})x + (w^{[2]}b^{[1]}) + b^{[2]}$<br>\n",
    "$a^{[2]} = w'x + b'$<br>\n",
    "\n",
    "This linear function doesn't add any information in the hidden layers so might as well don't use a neural network. The only situation where you can use a linear activation function is for the output layer in a regression problem.\n",
    "\n",
    "### Gradient descent for neural networks.\n",
    "To implement gradient desent we need to calculate the partial derivatives across the entire network as following.<br>\n",
    "\n",
    "<img src='img/img13.jpg' style=\"width:800px; height:150px\"/><br>\n",
    "\n",
    "- $dz^{[2]} = a^{[2]} - y$<br>\n",
    "- $dW^{[2]} = dz^{[2]}a^{[1]T}$<br>\n",
    "- $db^{[2]} = dz^{[2]}$<br>\n",
    "- $dz^{[1]} = W^{[2]T} dz^{[2]} * g\\prime^{[1]}(z^{[1]})$<br>\n",
    "- $dW^{[1]} = dz^{[1]}x^{T}$<br>\n",
    "- $db^{[1]} = dz^{[1]}$<br>\n",
    "\n",
    "In vectorized implementation for the multiple records.\n",
    "\n",
    "- $dZ^{[2]} = A^{[2]} - Y$<br>\n",
    "- $dW^{[2]} = \\frac{1}{m}dZ^{[2]}A^{[1]T}$<br>\n",
    "- $db^{[2]} = \\frac{1}{m}np.sum(dZ^{[2]},axis=1,keepdims=True)$<br>\n",
    "- $dZ^{[1]} = W^{[2]T}dZ^{[2]} * g\\prime^{[1]}(Z^{[1]})$<br>\n",
    "- $dW^{[1]} = \\frac{1}{m}dZ^{[1]}X^{T}$<br>\n",
    "- $db^{[1]} = \\frac{1}{m}np.sum(dZ^{[1]},axis=1,keepdims=True)$<br>\n",
    "\n",
    "#### Ramdom initialization\n",
    "To break simmetry (make the outputs of each activation node in the hidden layer different) we need to configure our initial parameters to random small numbers around 0. The initial parameters for $b$ can be 0.\n",
    "\n",
    "## Deep Neural Network\n",
    "### Deep L-layer neural network \n",
    "A deep learning NN is a multiple hidden layer neural network. A single hidden layer NN is known as a shallow NN.\n",
    "\n",
    "<img src='img/img14.jpg' style=\"width:500px; height:250px\"/><br>\n",
    "\n",
    "We'll use the following notation:\n",
    "- $L$; to denote the number of layers. The input layer is the \"0\" layer.\n",
    "- $n^{[l]}$; to denote the number of units in layer \"l\".\n",
    "- $a^{[l]}$; to thenote the number of activations in layer \"l\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward propagation in a Deep Network\n",
    "Given a single training x, in general:\n",
    "\n",
    "- $z^{[l]} = W^{[l]}a^{[l-1]} + b^{[l]}$\n",
    "- $a^{[l]} = g^{[l]}(z^{[l]})$\n",
    "\n",
    "For the whole data set in vectorized form:\n",
    "\n",
    "- $Z^{[l]} = W^{[l]}A^{[l-1]} + b^{[l]}$; $A^{[0]} = X$\n",
    "- $A^{[l]} = g^{[l]}(Z^{[l]})$\n",
    "\n",
    "### Getting dimensions right\n",
    "For the following deep neural network.\n",
    "\n",
    "<img src='img/img15.jpg' style=\"width:300px; height:150px\"/><br>\n",
    "\n",
    "We have:\n",
    "- $L=5$\n",
    "- $n^{[0]}=2$; $n^{[1]}=3$; $n^{[2]}=5$; $n^{[3]}=4$; $n^{[4]}=2$; $n^{[5]}=1$\n",
    "\n",
    "To validate dimesions for a single record:\n",
    "- $z^{[l]} : (n^{[l]},1)$\n",
    "- $W^{[l]} : (n^{[l]},n^{[l-1]})$\n",
    "- $b^{[l]} : (n^{[l]},1)$\n",
    "- $dW^{[l]} : (n^{[l]},n^{[l-1]})$\n",
    "- $db^{[l]} : (n^{[l]},1)$\n",
    "- $a^{[l]} : (n^{[l-1]},1)$\n",
    "\n",
    "In a vectorized implementation for \"m\" records:\n",
    "- $Z^{[l]} : (n^{[l]},m)$\n",
    "- $W^{[l]} : (n^{[l]},n^{[l-1]})$\n",
    "- $b^{[l]} : (n^{[l]},m)$\n",
    "- $dW^{[l]} : (n^{[l]},n^{[l-1]})$\n",
    "- $db^{[l]} : (n^{[l]},m)$\n",
    "- $A^{[l]} \\text{ or } X : (n^{[l-1]},m)$\n",
    "\n",
    "### Why deep representations?\n",
    "**Intuition about deep learning representation:**<br>\n",
    "<img src='img/img16.jpg' style=\"width:500px; height:200px\"/><br>\n",
    "\n",
    "**Circuit theory and deep learning:** There are functions you can compute with a \"small\" L-layer deep neural network that shallower networks require exponentially more hidden units to compute.<br>\n",
    "\n",
    "### Building blocks of deep neural networks\n",
    "**Example of implementation of a neural network:**<br>\n",
    "<img src='img/img17.jpg' style=\"width:400px; height:200px\"/><br>\n",
    "With this:<br>\n",
    "$W^{[l]} = W^{[l]} - \\alpha*dW^{[l]}$<br>\n",
    "$b^{[l]} = b^{[l]} - \\alpha*db^{[l]}$<br><br>\n",
    "**Note:** We store the cache $Z^{[l]}$ in Forward propagation to use it later in Backward propagation.\n",
    "\n",
    "### Forward and Backward Propagation\n",
    "#### Forward propagation:\n",
    "- Input $a^{[l-1]}$\n",
    "- Output $a^{[l]}$, cache $z^{[l]}$<br>\n",
    "\n",
    "Single record:<br>\n",
    "$z^{[l]} = W^{[l]}a^{[l-1]} + b^{[l]}$<br>\n",
    "$a^{[l]} = g^{[l]}(z^{[l]})$<br>\n",
    "Vectorized:<br>\n",
    "$Z^{[l]} = W^{[l]}A^{[l-1]} + b^{[l]}$; $A^{[0]} = X$<br>\n",
    "$A^{[l]} = g^{[l]}(Z^{[l]})$\n",
    "#### Backward propagation:\n",
    "- Input $da^{[l]}$\n",
    "- Output $da^{[l-1]}$, $dW^{[l]}$,$db^{[l]}$<br>\n",
    "\n",
    "Single record:<br>\n",
    "$dz^{[l]} = da^{[l]}*g\\prime^{[l]}z^{[l]}$<br>\n",
    "$dW^{[l]} = dz^{[l]}a^{[l-1]}$<br>\n",
    "$db^{[l]} = dz^{[l]}$<br>\n",
    "$da^{[l-1]} = W^{[l]T}dz^{[l]}$<br><br>\n",
    "Vectorized:<br>\n",
    "$dZ^{[l]} = dA^{[l]}*g\\prime^{[l]}(Z^{[l]})$<br>\n",
    "$dW^{[l]} = \\frac{1}{m} dZ^{[l]}A^{[l-1]T}$<br>\n",
    "$db^{[l]} = \\frac{1}{m} np.sum(dZ^{[l]},axis=1,keepdims=True)$<br>\n",
    "$dA^{[l-1]} = W^{[l]T}dZ^{[l]}$<br>\n",
    "\n",
    "### Parameters vs Hyperparameters\n",
    "- **Parameters:** $W^{[1]}, b^{[1]}, W^{[2]}, b^{[2]}, W^{[3]}, b^{[3]}...$<br>\n",
    "- **Hyperparamenters:**\n",
    "    - Learning rate $\\alpha$\n",
    "    - Number of interations\n",
    "    - Number of hidden layers L\n",
    "    - Hidden units\n",
    "    - Choice of activation function\n",
    "\n",
    "### Summary\n",
    "<img src='img/img18.jpg' style=\"width:600px; height:500px\"/><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Course 2 - Improving Deep Neural Networks\n",
    "## Practical aspects of Deep Learning\n",
    "### Setting up your ML application\n",
    "#### Train / Dev / Test sets\n",
    "Applied Machine Learning is a highly iterative process.<br>\n",
    "<img src='img/img19.jpg' style=\"width:500px; height:200px\"/><br>\n",
    "For the different applications of ML intuitions in certain areas often do not transfer to other areas.<br>\n",
    "To go quickly throught this iterative process we need to set the data in train/dev/test sets. In traditional ML the train/dev/test sets ratio is 60%/20%/20% but for big data, smaller sets for dev and test are considered best practices; 98%/1%/1%/ is a common choice.<br>\n",
    "For **Mismatched train/test distributions**, where the training set and the test/dev sets come from different sources, we have to make sure that they come from the same distribution.\n",
    "#### Bias and Variance\n",
    "Trade-off of a classification model:\n",
    "\n",
    "|Classification| High variance | High bias | High variance and bias | Low bias and variance|\n",
    "|:-|:-:|:-:|:-:|:-:|\n",
    "|Train Set Error| 1% | 15% | 15% | 0.5% |\n",
    "|Dev Set Error| 11% | 16% | 30% | 1% |\n",
    "\n",
    "#### Basic recipe for Machine Learning\n",
    "|Problem| Possible Solution|\n",
    "|:-|:-|\n",
    "|High bias| Bigger network; Larger training set; Change the NN architecture|\n",
    "|High Variance| More data; Regularization; Change the NN architecture |\n",
    "\n",
    "### Regularizing Neural Networks\n",
    "#### Regularization\n",
    "\n",
    "**For logistic regression:**<br>\n",
    "For $min J(w,b)$:<br><br>\n",
    "$J(w,b) = \\frac{1}{m} \\sum^{m}_{i=1}(\\hat{y}^{(i)},y^{(i)}) + \\frac{\\lambda}{2m}||w||^{2}_2$<br><br>\n",
    "$L_2 \\text{regularization}: ||w||^{2}_2 = \\sum^{n_x}_{j=1}w^{2}_{j} = w^{T}w$<br><br>\n",
    "$L_1 \\text{regularization}: \\frac{\\lambda}{2m}\\sum^{n_x}_{j=1}|w|_{j} = \\frac{\\lambda}{2m}||w||_l$; w will be sparse<br><br>\n",
    "$\\lambda = \\text{regularization parameter}$<br><br>\n",
    "\n",
    "**For Neural networks:**<br>\n",
    "For $min J(w^{[1]},b^{[1]},...,w^{[L]},b^{[L]})$:<br><br>\n",
    "$J = \\frac{1}{m}\\sum^{m}_{i=1}L(\\hat{y}^{(i)},y^{(i)}) + \\frac{\\lambda}{2m}\\sum^{L}_{l=1}||w^{[l]}||^{2}$<br><br>\n",
    "$||w^{[l]}||^{2}_{F} = \\sum^{n^{[l]}}_{i=1}\\sum^{n^{[l-1]}}_{j=1}(w^{[l]}_{ij})^{2}$; **\"Frobenius norm\"**<br><br>\n",
    "$dw^{[l]} = \\text{(From Backprop)} + \\frac{\\lambda}{m} W^{[l]}$<br><br>\n",
    "$W^{[l]} = W^{[l]} - \\alpha dW^{[l]}$; \"Weight decay\"\n",
    "\n",
    "#### Dropout regularization\n",
    "\n",
    "It consists in randomly eliminate nodes in the network, as following:<br>\n",
    "<img src='img/img20.jpg' style=\"width:300px; height:150px\"/><br>\n",
    "\n",
    "**Inverted dropout;** We can implement this regularization as follows:<br>\n",
    "for layer 3:<br>\n",
    ">d3 = np.random.rand(a3.shape[0],a3.shape[1])<keep_prob<br>\n",
    "a3 = np.multiply(a3,d3)<br>\n",
    "a3/= keep_prop<br>\n",
    "*For test time we can't use drop out*<br>\n",
    "\n",
    "#### Other regularization methods\n",
    "- Increase the training data by transforming existing examples. For e.g:<br>\n",
    "<img src='img/img21.jpg' style=\"width:300px; height:150px\"/><br>\n",
    "- Early stopping; stop the #of iterations to avoid overfitting.<br>\n",
    "<img src='img/img22.jpg' style=\"width:300px; height:250px\"/><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up your optimization problem\n",
    "#### Normalizing inputs.\n",
    "To optimize gradient descent it's necessary to normalize the features of the model. Here is an intuition.<br>\n",
    "\n",
    "<img src='img/img23.jpg' style=\"width:500px; height:250px\"/><br>\n",
    "\n",
    "By setting every feature to zero mean and same variance we help the learning algorithm to run faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "x = np.linspace(1,5,50)\n",
    "y = 2 + x + 3*(np.random.randn(50))\n",
    "plt.scatter(x,y,s=7)\n",
    "plt.ylim(-8,8)\n",
    "plt.xlim(-5,5)\n",
    "plt.hlines(0,-5,5)\n",
    "plt.vlines(0,-8,8)\n",
    "plt.title('Not normalized data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAEICAYAAABCnX+uAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAWsUlEQVR4nO3dfZBldX3n8fdnZmQUmgfNjJLAjGhU1JgoaweNJmEio0UIq/7hGs1qNKlkqkziggtlVLZMshVTu0nwoUpLataYyMoGFXW1YkwQS7CyK6zD0yY44hIVB+RhRkEdMTPMzHf/uLczl6af77kP5973q6qLPvec/p1f3x4+/evv73fOSVUhSWqvdaPugCSpPwa5JLWcQS5JLWeQS1LLGeSS1HIGuSS1nEEujUiSbybZPup+qP0McjUqyb9Psn+Bj0ry9lH3r626799TRt0PjSeDXI2qqsuraqb3A7gAuBf4b6ttL8mGxjspTRiDXAOV5AzgXcCrquru7msnJvmLJHcnuSvJHydZ3933+iT/K8m7knwX+MMk65L8pyR3JLkvyWVJTlzkfNuS3Jnkzd1j707y8iTnJvlaku8meVvP8euSvCXJPyf5TpKPJnlcz/6PJbknyfeSfDHJT/Xs+6sk70vymSQ/SHJ9kp9c4r14bfd7+E6Si+ftOzPJl5I80O3ze5Mc0933xe5ht3T/uvnVJI9N8jdJ9ia5v/v5qav9+WgyGOQamCQnAVcCf1xV1/Ts+hBwCHgKcAbwEuC3evY/D/g68HjgHcDrux+/BDwZmAHeu8SpTwYeDZwCvJ3OXwKvAZ4L/ALw9iRP7h77H4CXA2cBPwHcD7yvp63PAk/t9uVG4PJ553o18EfAY4Hbu/1d6L14JvB+4LXd8/wY0Bu8h4E3AZuAnwPOBn4HoKp+sXvMs7t/5XyEzv+7fwk8EdgK/GiZ90STrKr88KPxDyDAp7of6Xn9CcAB4DE9r70a+EL389cD35rX1ueB3+nZPh14CNiwwHm30Qm19d3t44ECntdzzA3Ay7uf7wbO7tn340u0fVK3rRO7238FfKBn/7nAVxd5P94OXNGzfRxwENi+yPEXAJ/s2S7gKUu8388B7h/1z92P0XxYf9Sg/D7wLOC51U2aricCjwLuTjL32jpgT88xvZ9DZwR7R8/2HcAGOr8U7lrg3N+pqsPdz3/U/e+9Pft/RGdUP9efTyY50rP/MPCEJPfQGWH/O2AzMHfMJuB73c/v6fm6B3vane8ner+vqvphku/MbSd5GvBOYBY4tvv93bBIWyQ5lk7J6hw6fw0AHJ9kfc/3rilhaUWNS7INuBh4RVU9MG/3Hjoj8k1VdVL344Sq+qmeY+bfkvPbdAJ3zlY6pZl76d8e4Jd7+nJSVT26qu4Cfg14GbAdOBE4rfs1WbipJd0NbJnb6Abxj/Xsfz/wVeCpVXUC8LZlznMhnb9Mntc9fq78spa+qeUMcjUqyY8DVwAXVNVN8/dXZ8LzKuCSJCd0Jxt/MslZSzT718CbkjwpyQzwJ8BHqupQA12+FHhHkid2+785ycu6+46n80vnO3RGyX/Sx3muBM5L8vPdScz/zMP//zse+D6wP8nTgTfM+/p76cwP9B7/I+CB7uTsH/TRN7WcQa6m/Tadksd7FlhLfmn3mF8HjgG+Qmdy8Uo6tenFfBD478AXgW8A/wK8saH+vgf4NHBVkh8A19GZbAW4jE4Z565uX69b60mq6lbgd4H/QWd0fj9wZ88hF9H5C+AHdCZnPzKviT8EPtRd1fJK4N3AY4B93X793Vr7pvbLw8uXkqS2cUQuSS3XSJAneVOSW5P8U5K/TvLoJtqVJC2v7yBPcgqdiypmq+pZwHrgVf22K0lamaZKKxuAx3Tvi3EsneVikqQh6PuCoKq6K8mfA9+isxzqqqq6av5xSXYAOwCOO+645z796U/v99RSo2677TYATj/99BH3RFrYDTfcsK+qNs9/ve9VK0keC3wc+FXgAeBjwJVV9eHFvmZ2drZ27drV13mlpm3btg2Aa665ZqT9kBaT5Iaqmp3/ehOlle3AN6pqb1U9BHwCeEED7UqSVqCJIP8W8Pwkx6Zz84yz6dyISJI0BH0HeVVdT+fKvBuBf+y2ubPfdiVJK9PI3Q+r6g/wXg+SNBJe2SlJLWeQS1LLGeSS1HIGuSS1nEEuSS1nkEtSyxnkktRyBrkktZxBLkktZ5BLUssZ5JLUcga5JLWcQS5JLWeQS1LLGeSS1HIGuSS1nEEuSS1nkEtSyzUS5ElOSnJlkq8m2Z3k55poV5K0vEae2Qm8B/i7qnpFkmOAYxtqV5K0jL6DPMkJwC8CrweoqoPAwX7blSStTBOllScDe4G/THJTkg8kOa6BdiVJK9BEkG8A/g3w/qo6A/gh8Jb5ByXZkWRXkl179+5t4LSSJGgmyO8E7qyq67vbV9IJ9oepqp1VNVtVs5s3b27gtJIkaCDIq+oeYE+S07svnQ18pd92JUkr09SqlTcCl3dXrHwd+I2G2pUkLaORIK+qm4HZJtqSJK2OV3ZKUssZ5JpY+/Yf4PO772Xf/gOj7oo0UE3VyKWxsm//AbZfci2Hjhxhw7p1XH3hWWya2TjqbkkD4YhcE+mWPQ9w6MgR9h84zKEjR7hlzwOj7pI0MI7INZGeveUkNqxbx8xG2LBuHc/ectKouyQNjEGuibRpZiNXX3gWt+x5gGdvOcmyiiaaQa6JtWlmI2c/4wmj7oY0cNbIJanlDHJpCrk0c7JYWpGmjEszJ48jcg2EI77x5dLMyeOIXI1zxDfeXJo5eQxyNa53xDezsbPt6pHx4dLMyWOQq3GO+MafSzMni0Guxjnik4bLINdAOOKThsdVK5LUcga5JLWcQS6NCdfea60aq5EnWQ/sAu6qqvOaaleaBq69Vz+aHJGfD+xusD1pJEYxMm7iaktH9NOrkRF5klOBXwHeAfzHJtqURuGhw0cGNjLet//Aoksy+11774h+ujVVWnk38Gbg+MUOSLID2AGwdevWhk4rNWv/gUMcHsBVqcsF7WJr75cK/15eTTvd+i6tJDkPuK+qbljquKraWVWzVTW7efPmfk8rDcTMxg3dkfH6Rq9KXUnpZG7tfW+Ib7/kWs6/4ia2X3LtkiWToyP6ZvutdmhiRP5C4KVJzgUeDZyQ5MNV9ZoG2paG6lHr1w3kqtS1lE5WM8r2atrp1neQV9VbgbcCJNkGXGSIq80GcVXqWoJ2fvhvedyxfH73vYt+vVfTTi8v0ZeGZLVB2xv+Wx53LK+89EtOZmpBjV4QVFXXuIZcas5c+O/57oM+DEKLckQutYC3BtZSDHKpBfpdnqjJZpBLLTG/xu5FQJrjTbOklvIhyprjiFxqKevmmmOQSy3lRUCaY5BLLeZFQAJr5JLUega5JLWcQS5JLWeQS1LLGeSS1HIGuSS1nEEuSS1nkEtSyxnkktRyBrkktZxBLkkt13eQJ9mS5AtJdie5Ncn5TXRMkrQyTdw06xBwYVXdmOR44IYkn6uqrzTQtiRpGX2PyKvq7qq6sfv5D4DdwCn9titNqn37D/D53feyb/+BUXdFE6LR29gmOQ04A7h+gX07gB0AW7dubfK0Umv4eDYNQmOTnUlmgI8DF1TV9+fvr6qdVTVbVbObN29u6rRSq/h4Ng1CI0Ge5FF0QvzyqvpEE21Kk2B+GeXo49nW+3g2Nabv0kqSAH8B7K6qd/bfJWkyLFZG8fFsaloTI/IXAq8FXpTk5u7HuQ20K7XaYmWUucezGeJqSt8j8qr6ByAN9EWaKD7lXsPiw5elAbGMomExyKUB8in3GgbvtaJleQHL9PFn3i6OyLUkL2CZPv7M28cR+ZRbbuQ1KRewOMJcuUn5mU8TR+RTbCUjr0lYeeEIc3Um4Wc+bQzyKdY78prZ2NmePzE3CSsvVvJ96qhJ+JlPG0srU2yll4u3/QKWtV4Wv5pyzLBLN4M+X9t/5tPGEfkUG8eR1779Bxrvz1q+z9WUY4ZdurFUpPkckU+5cRp5zQXU+VfcxPZLrm10tLna73M1E37Dnhx0MlLzGeQaG8MOqKXKE6spxwz7jobeQVHzWVrR2BjmaomFyhO9VlOOGXaJaiXnG0SJSuPLINfYGGYgLrSSZaH+rHR1y7AvxV/qfNbQp4+lFY2VYdXsJ7k8YQ19+jgi11QaxxU7TfGCnuljkGtqraYc0qaa8yT/ktLCDHJpGW2sOXv73OlijVxahjVnjbtGgjzJOUluS3J7krc00aa0kFHcxXCSJ0bn8y6R7dR3aSXJeuB9wIuBO4EvJ/l0VX2l37alXqMqcUxLzbmNJSR1NFEjPxO4vaq+DpDkCuBlwKJBftttt7Ft27YGTq1pcv+DB7n9vv0cPlKsXxfO/swMjz32mMbav/nmmwGm9t/moN9fDU4TpZVTgD0923d2X3uYJDuS7Eqy66GHHmrgtGqzhw4f4f4HD/LQ4SMr/pqZjRsIYf26EMLMRufqm+T7215N/KSywGv1iBeqdgI7AWZnZ+uaa65p4NRqo7k/4Q8fOcIPV/kn/HLLAPtZJjg3Ep/mf5ttWmY5jZKF4raZIL8T2NKzfSrw7Qba1YTq50EPXpo+WC5bbKcmSitfBp6a5ElJjgFeBXy6gXY1oQa1CsRlgppWfY/Iq+pQkt8D/h5YD3ywqm7tu2eaWINaBeKl6ZpWjcxmVNXfAn/bRFuaDr1/wjdVl52WZYLSfE5La02aCt+m69qTUuMd5qSjE5ztZ5Br1ZoMX59w/0jDnLR1gngyeK8VrVqTk4pNTXxO0qXlw5y0dYJ4Mjgi16o1OanYRF170kaVw5y0dYJ4MhjkWrWmJxX7rWtPWnlmmJO2ThBPBoNcazJOk4qTOKoc5vs7Tj9LrY1BrtZzVKlp52SnJsKwHtrcRpM0EayFOSJXazW5/nnf/gPc/+DBibvj36RNBGthjsjVt1GM+OYC6vwrbmL7Jdf2de65tm6/bz+37Pnesm21aYTbOxF88PBhLvvf32xFv7U6kzX80NCNasTX5EqVubY6D1RYuq22jXDnJoKPPab40cEjfOAfvsFlX7pj7Put1XFErr6M6oKSJu+gONfW3AMVlmqrbRfQzE0E/9bPP5nHHLOeBw+2o99aHUfk6suolv41uVJlrq2zPzPDzMYNS7bVxqWOm2Y28usvOI3LvnQH61rUb61cqh7xMJ+Bm52drV27dg39vBqMSbnp0kqfENTW77et/dZRSW6oqtn5rzsiV9+m7YKStn6/be23lmeNXAtaaGVGm1ZrSNPEEbkeYaGVGUCrVmtI08QRuR5hoZUZbVutIU2TvkbkSf4M+LfAQeCfgd+oKv8Pb7nFVma0bbWGNC36La18Dnhr9wHM/xV4K/D7/XdLo7TY0j5vTCWNp76CvKqu6tm8DnhFf93RuFhohYOrHqTx1GSN/DeBzy62M8mOJLuS7Nq7d2+Dp5Wk6bbsiDzJ1cDJC+y6uKo+1T3mYuAQcPli7VTVTmAndC4IWlNvJUmPsGyQV9X2pfYneR1wHnB2jeIyUUmacv2uWjmHzuTmWVX1YDNdkiStRr818vcCxwOfS3Jzkksb6JMkaRX6XbXylKY6IklaG6/slKSWM8glqeUMcmmEvKOkmuDdD6URadvzPzW+HJFLI+IdJdUUR+TSiLTx+Z8aTwa5NCJNPkBa083Sihrl5N3qzN1R0hBXPxyRqzHTOHnnk+k1DgxyNaZ38m5mY2e7ifuXj2tYTuMvLo0ng1yNGcTk3TiH5aB+cUmrZZCrMYOYvBvnsHTVicaFQa5GNf04uHEOS1edaFwY5Bpr4x6WPsdU48Ag19gzLKWluY5cklrOIJekljPIJanlGgnyJBclqSSbmmhPkrRyfQd5ki3Ai4Fv9d8dafC8H4wmTROrVt4FvBn4VANtSQM1zleKSmvV14g8yUuBu6rqlhUcuyPJriS79u7d289ppTXzYQ6aRMuOyJNcDZy8wK6LgbcBL1nJiapqJ7ATYHZ2tlbRR6kx43ylqLRWywZ5VW1f6PUkPw08CbglCcCpwI1JzqyqexrtpdSQcb9SVFqLNdfIq+ofgcfPbSf5JjBbVfsa6Jc0MF4pqknjOnJJarnGgryqTnM0ruW49E9qnjfN0tC49E8aDEsrGhqX/kmD4YhcQ+PSP2kwDHINjUv/pMGwtKKhmlv6N8kh7oSuhs0RudQgJ3Q1Co7IpQY5oatRcEQuNcgJXY2CQa6xtW//gdZNjDqhq1EwyDWW2lxr9l4uGjZr5BpL1pqllXNErrFkrVlaOYNc/2qcatLWmqWVM8gFDLYmvdZfENaapZUxyAU8vCY9s7Gz3USItnnSUmoLJzsF9Nak1zdak3bSUho8R+QCBleTdtJSGjyDXP9qEDVpJy2lweu7tJLkjUluS3Jrkj9tolOaLNNwx0NplPoakSf5JeBlwM9U1YEkj2+mW5Kklep3RP4G4L9U1QGAqrqv/y5Jklaj3yB/GvALSa5Pcm2Sn22iU5KklVu2tJLkauDkBXZd3P36xwLPB34W+GiSJ1dVLdDODmAHwNatW/vpsySpx7JBXlXbF9uX5A3AJ7rB/X+SHAE2AXsXaGcnsBNgdnb2EUEvSVqbfksr/xN4EUCSpwHHAPv67ZQkaeX6XUf+QeCDSf4JOAi8bqGyiiRpcPoK8qo6CLymob5IktbAe61IUssZ5JLUcga5JLWcQS5JLWeQS1LLGeSS1HIGuSS1nEEuSS1nkEtSyxnkktRyBrkktZxBLkktZ5BLUssZ5JLUcga5JLWcQS5JLWeQS1LLGeSS1HIGuSS1XF9BnuQ5Sa5LcnOSXUnObKpjkqSV6XdE/qfAH1XVc4C3d7clSUPUb5AXcEL38xOBb/fZniRplVJVa//i5BnA3wOh80vhBVV1xyLH7gB2dDdPB25b84mbsQnYN+I+jAvfi6N8L47yvThqXN6LJ1bV5vkvLhvkSa4GTl5g18XA2cC1VfXxJK8EdlTV9iZ6O2hJdlXV7Kj7MQ58L47yvTjK9+KocX8vNix3wFLBnOQy4Pzu5seADzTUL0nSCvVbI/82cFb38xcB/6/P9iRJq7TsiHwZvw28J8kG4F84WgNvg52j7sAY8b04yvfiKN+Lo8b6vehrslOSNHpe2SlJLWeQS1LLGeRAkouSVJJNo+7LqCT5syRfTfJ/k3wyyUmj7tOwJTknyW1Jbk/yllH3Z1SSbEnyhSS7k9ya5Pzlv2qyJVmf5KYkfzPqvixk6oM8yRbgxcC3Rt2XEfsc8Kyq+hnga8BbR9yfoUqyHngf8MvAM4FXJ3nmaHs1MoeAC6vqGcDzgd+d4vdizvnA7lF3YjFTH+TAu4A307ndwNSqqquq6lB38zrg1FH2ZwTOBG6vqq9X1UHgCuBlI+7TSFTV3VV1Y/fzH9AJsFNG26vRSXIq8CuM8XUyUx3kSV4K3FVVt4y6L2PmN4HPjroTQ3YKsKdn+06mOLzmJDkNOAO4frQ9Gal30xnsHRl1RxbT7zrysbfMLQbeBrxkuD0anaXei6r6VPeYi+n8aX35MPs2BrLAa1P9V1qSGeDjwAVV9f1R92cUkpwH3FdVNyTZNur+LGbig3yxWwwk+WngScAtSaBTSrgxyZlVdc8Quzg0y90HJ8nrgPOAs2v6LjC4E9jSs30qU3w3zySPohPil1fVJ0bdnxF6IfDSJOcCjwZOSPLhqnrNiPv1MF4Q1JXkm8BsVY3DHc6GLsk5wDuBs6pq76j7M2zdq5O/RudGcHcBXwZ+rapuHWnHRiCdkc2HgO9W1QWj7s+46I7IL6qq80bdl/mmukauh3kvcDzwue4Tny4ddYeGqTvR+3t0bsu8G/joNIZ41wuB1wIv6v5buLk7ItWYckQuSS3niFySWs4gl6SWM8glqeUMcklqOYNcklrOIJekljPIJanl/j8Os7E7hbkGkgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "u,u2 =np.mean(x), np.mean(y)\n",
    "plt.scatter(x-u,y-u2,s=7)\n",
    "plt.ylim(-8,8)\n",
    "plt.xlim(-5,5)\n",
    "plt.hlines(0,-5,5)\n",
    "plt.vlines(0,-8,8)\n",
    "plt.title('Zero mean data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "v,v2 =np.std(x), np.std(y)\n",
    "plt.scatter((x-u)/v,(y-u2)/v2,s=7)\n",
    "plt.ylim(-8,8)\n",
    "plt.xlim(-5,5)\n",
    "plt.hlines(0,-5,5)\n",
    "plt.vlines(0,-8,8)\n",
    "plt.title('Normalized data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vanishing / Exploding gradients\n",
    "For certain deep architectures it's possible that the gradients increase/decrease exponentially for every layer that you add. Here's an intuition for a linesar NN.\n",
    "\n",
    "<img src='img/img24.jpg' style=\"width:500px; height:80px\"/><br>\n",
    "\n",
    "$\\hat{y} = W^{[L]} W^{[l-1]} W^{[l-2]} ... W^{[3]} W^{[2]} W^{[1]} X$<br>\n",
    "\n",
    "Assuming W is an slightly bigger 2x2 identity matrix:\n",
    "\n",
    "$\\hat{y} = W^{[L]} \\begin{bmatrix} 1.5 & 0 \\\\ 0 & 1.5 \\end{bmatrix}^{L-1} X$<br>\n",
    "\n",
    "For this configuration the gradients increase at a rate of: $1.5^{L}$\n",
    "#### Weight initialization for Deep Networks\n",
    "\n",
    "For a single neuron.<br><br>\n",
    "<img src='img/img25.jpg' style=\"width:180px; height:110px\"/><br>\n",
    "\n",
    "$Z = W_1 X_1 + W_2 X_2 + ... W_n X_n$<br>\n",
    "$\\text{large } n \\rightarrow \\text{smaller } W_i$<br>\n",
    "$\\text{Var}(W_i) = \\cfrac{2}{n}$<br>\n",
    "\n",
    "For RELU:<br>\n",
    "$W^{[l]} = \\text{np.random.randn(shape)} \\cdot \\text{np.sqrt}\\Big(\\cfrac{2}{n^{[l-1]}}\\Big)$\n",
    "\n",
    "For tanh:<br>\n",
    "$\\sqrt{\\frac{1}{n^{[-1]}}}$<br>\n",
    "\n",
    "Xavier initialization:<br>\n",
    "$\\sqrt{\\frac{2}{n^{[l-1]}+n^{[l]}}}$<br>\n",
    "\n",
    "#### Numerical approximation of gradients\n",
    "For a function: $f(\\theta) = \\theta^{3}$;<br>\n",
    "\n",
    "$\\cfrac{f(\\theta+\\epsilon)-f(\\theta-\\epsilon)}{2\\epsilon} \\approx g(\\theta)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.linspace(0,5,100)\n",
    "y = np.power(x,3)\n",
    "plt.scatter(4+0.01,(4+0.01)**3)\n",
    "plt.scatter(4-0.01,(4-0.01)**3)\n",
    "plt.scatter(4,(4)**3)\n",
    "plt.plot(x,y)\n",
    "plt.xlim(3.8,4.2)\n",
    "plt.ylim(62,65)\n",
    "plt.hlines((4-0.01)**3,4-0.01,4+0.01,colors='r')\n",
    "plt.vlines(4+0.01,(4-0.01)**3,(4+0.01)**3,colors='r')\n",
    "plt.annotate('2e',xy=(3.995,63.3))\n",
    "plt.annotate('f(x+e)-f(x-e)',xy=(4.015,64))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient checking\n",
    "1. Take all parameters $W^{[1]},b^{[1]},...,W^{[L]},b^{[L]}$ and reshape into a big vector $\\theta$.\n",
    "\n",
    "2. Take all derivatives $dW^{[1]},db^{[1]},...,dW^{[L]},db^{[L]}$ and reshape into a big vector $d\\theta$.\n",
    "\n",
    "3. Question: is $d\\theta$ the gradient of $J(\\theta)$?\n",
    "\n",
    "4. For each i:\n",
    "    - $d\\theta^{[i]}_{\\text{approx}} = \\cfrac{J(\\theta_1, \\theta_2,...,\\theta_i + \\epsilon,...) - J(\\theta_1, \\theta_2,...,\\theta_i - \\epsilon,...)}{2\\epsilon}$\n",
    "    \n",
    "5. Is $d\\theta_{\\text{approx}} \\approx d\\theta$?;\n",
    "    - Check: $\\cfrac{||d\\theta_{\\text{approx}}-d\\theta||_{2}}{||d\\theta_{\\text{approx}}||_2 + ||d\\theta||_2} \\approx 0 $\n",
    "\n",
    "#### Gradient checking implementation notes\n",
    "- Don't use in training - only debug\n",
    "- If alogorithm fails grad check, look at components to try to identify bug.\n",
    "- Remember regularization.\n",
    "- Doesn't work with dropout\n",
    "- Run at random intialization; perhaps again after some training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization algorithms\n",
    "### Mini-batch gradient descent\n",
    "Vectorization allows you to efficiently compute on *m* examples.<br>\n",
    "$X_{(n,m)} = [x^{[1]},x^{[2]},x^{[3]},...,x^{[m]}]$<br>\n",
    "$Y_{(1,m)} = [y^{[1]},y^{[2]},y^{[3]},...,y^{[m]}]$<br>\n",
    "\n",
    "What if $m=5000000$?; We can run gradient decent in mini batches of 1000 each.<br>\n",
    "Minibatch t : $X^{\\{t\\}}, Y^{\\{t\\}}$<br>\n",
    "\n",
    "**Implementation:**<br>\n",
    "for t = 1,...,5000:<br>\n",
    "   > Forward propagation on $X^{\\{t\\}}$:\n",
    "        >> $Z^{[1]} = W^{[1]}X{\\{t\\}} + b^{[1]}$<br>\n",
    "        $A^{[1]} = g^{[1]}(Z^{[1]})$<br>\n",
    "        ...<br>\n",
    "        $A^{[L]} = g^{[L]}(Z^{[L]})$<br>\n",
    "        Compute cost $J^{[t]} = \\frac{1}{1000} \\sum^{l}_{i=1}L(\\hat{y}^{(i)},y^{(i)})+ frac{\\lambda}{2 \\cdot 1000}\\sum^{l}_{j=1}||w^{[l]}||^{2}_{F}$<br>\n",
    "        Back propagation to comute gradients $J^{\\{t\\}} (\\text{using}(X^{\\{t\\}},Y^{\\{t\\}}))$<br>\n",
    "        $W^{[l]} = W^{[l]} - \\alpha dW^{[l]}, b^{[l]} = b^{[l]} - \\alpha db^{[l]}$\n",
    "\n",
    "### Understanding mini-batch gradient descent\n",
    "\n",
    "**Training Batch gradient descent**<br>\n",
    "<img src='img/img26.jpg' style=\"width:250px; height:200px\"/><br>\n",
    "\n",
    "**Training mini-batch gradient descent**<br>\n",
    "<img src='img/img27.jpg' style=\"width:250px; height:200px\"/><br>\n",
    "\n",
    "**Choosing mini-batch size:**<br>\n",
    "\n",
    "If mini-batch size = m: Batch gradient descent. $(X^{\\{t\\}},Y^{\\{t\\}})=(X,Y)$<br>\n",
    "If mini-batch size = 1: Stochastic gradient descent. $(X^{\\{t\\}},Y^{\\{t\\}}) = (X^{(1)},Y^{(1)})$<br>\n",
    "In practice 1 < mini-batch size < m.\n",
    "\n",
    "**Practical guidelines:**<br>\n",
    "- If small training set: Use batch gradient descent $(m\\leq2000)$. \n",
    "- Choose a power of 2 (because of how computer memory works); e.g.: $2^6,2^6,2^8...$.\n",
    "- Make sure that the minibatch fits in CPU/GPU memory.\n",
    "\n",
    "### Exponentially weighted averages\n",
    "\n",
    "Formula: $V_t = \\beta V_{t-1} (1-\\beta)\\theta_t$; for e.g.<br>\n",
    "$\\beta = 0.9$; Averaging the 10 previous 10 temperature.<br>\n",
    "$\\beta = 0.98$; Averaging 50 days.<br>\n",
    "$\\beta = 0.5$; Averaging 2 days.<br>\n",
    "\n",
    "<img src='img/img28.jpg' style=\"width:350px; height:200px\"/><br>\n",
    "\n",
    "### Understanding exponentially weighted averages\n",
    "\n",
    "For, $v_t = \\beta v_{t-1} + (1 - \\beta)\\theta_{t}$<br>\n",
    "$v_{100} = 0.9v_{99} + 0.1 \\theta_{100}$<br>\n",
    "$v_{99} = 0.9v_{98} + 0.1 \\theta_{99}$<br>\n",
    "$v_{98} = 0.9v_{97} + 0.1 \\theta_{98}$<br>\n",
    "...<br>\n",
    "\n",
    "Combining this equations;<br>\n",
    "$v_{100} = 0.1 \\theta_{100} + 0.9(0.1\\theta_{99} + 0.9v_{98})$<br>\n",
    "$v_{100} = 0.1 \\theta_{100} + 0.1 \\cdot 0.9 \\cdot \\theta_{99} + 0.1 \\cdot 0.9^2 \\cdot \\theta_{98} + 0.1 \\cdot 0.9^3 \\cdot \\theta_{97} + ... $<br>\n",
    "\n",
    "This corresponds to a exponentially decaying function. All the coefficients add up to $\\approx 1.0$.<br>\n",
    "Also; $0.9^{10} \\approx 0.35 \\approx \\frac{1}{e}$. Because of  this: $(1-\\epsilon)^{\\frac{1}{\\epsilon}} = \\frac{1}{e}$ This averages aroud 50 periods of time.\n",
    "\n",
    "**Implementing exponentially weighted averages**<br>\n",
    "Initiallize:\n",
    ">$v_{\\theta} = 0$<br>\n",
    "$v_{\\theta} = \\beta v + (1-\\beta)\\theta_1$<br>\n",
    "$v_{\\theta} = \\beta v + (1-\\beta)\\theta_2$<br>\n",
    "...<br>\n",
    "\n",
    "So;<br>\n",
    "- $v_\\theta = 0$<br>\n",
    "- repeat{\n",
    "    - get next $\\theta_t$<br>\n",
    "    $v_\\theta = \\beta v_\\theta + (1-\\beta)\\theta_t$<br>\n",
    "    }<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias correction\n",
    "For the first periods of time, because there is not information about the previous days, this will happen (purple line).\n",
    "\n",
    "<img src='img/img29.jpg' style=\"width:350px; height:200px\"/><br>\n",
    "\n",
    "To solve this, instead of taking $v_t$ we should take $\\cfrac{v_t}{1-\\beta^t}$.<br>\n",
    "When $t=2: 1-\\beta^t = 1-(0.98)^2 = 0.0396$<br>\n",
    "$\\cfrac{v_2}{0.0396} = \\cfrac{0.0196\\theta_1 + 0.02\\theta_2}{0.0396}$<br>\n",
    "\n",
    "This solves the problem for the initial periods.\n",
    "\n",
    "### Gradient descent with momentum\n",
    "\n",
    "The basic idea is to compute an exponentially weighted average of the gradients to update paramters. To implement this:<br>\n",
    "\n",
    "On iteration $t$:<br>\n",
    ">   Compute $dW,db$ on current mini-batch.<br>\n",
    ">>    $v_{dW} = \\beta v_{dW} + (1-\\beta)dW$<br>\n",
    "    $v_{db} = \\beta v_{db} + (1-\\beta)db$<br>\n",
    "    $ W = W - \\alpha v_{dW} ; b = b - \\alpha v_{db}$<br>\n",
    "\n",
    "This will take a more straight forward path towards the local/global minimum.\n",
    "\n",
    "### RMSprop (Root Mean Square Propagation)\n",
    "\n",
    "On iteration $t$:<br>\n",
    "> Compute $dW,db$ on current mini-batch.<br>\n",
    ">> $S_{dW} = \\beta S_{dW} + (1-\\beta)dW^2$<br>\n",
    "$S_{db} = \\beta S_{db} + (1-\\beta)db^2$<br>\n",
    "$ W = W - \\alpha \\cfrac{dW}{\\sqrt{S_{dW}}} ; b = b - \\alpha \\cfrac{db}{\\sqrt{S_{db}}}$\n",
    "\n",
    "This will shrink the gradient steps in the direction that takes the bigger step.\n",
    "\n",
    "### Adam optimization algorithm\n",
    "\n",
    "Initiallize: $v_{dW}=0, S_{dW}=0,v_{db}=0, S_{db}=0$<br>\n",
    "\n",
    "On interation $t$:<br>\n",
    "> Compute $dW, db$ using current minibatch<br><br>\n",
    "$v_{dW}=\\beta_1 v_{dW}+(1-\\beta_1)dW,v_{db}=\\beta_1 v_{db}+(1-\\beta_1)db$<br>\n",
    "$S_{dW}=\\beta_2 S_{dW}+(1-\\beta_2)dW^2,S_{db}=\\beta_2 S_{db}+(1-\\beta_2)db^2$<br>\n",
    "$v_{dW}^{\\text{corrected}} = \\cfrac{v_{dW}}{(1-\\beta^t_1)},v_{db}^{\\text{corrected}} = \\cfrac{v_{db}}{(1-\\beta^t_1)}$<br>\n",
    "$S_{dW}^{\\text{corrected}} = \\cfrac{S_{dW}}{(1-\\beta^t_2)},S_{db}^{\\text{corrected}} = \\cfrac{S_{db}}{(1-\\beta^t_2)}$<br>\n",
    "$W = W-\\alpha \\cfrac{v_{dW}^{\\text{corrected}}}{\\sqrt{S_{dW}^{\\text{corrected}}}+\\epsilon},b = b-\\alpha \\cfrac{v_{db}^{\\text{corrected}}}{\\sqrt{S_{db}^{\\text{corrected}}}+\\epsilon}$\n",
    "\n",
    "**Recomended hyperparamter choice:**<br>\n",
    "- $\\alpha$: needs to be tuned.<br>\n",
    "- $\\beta_1$: 0.9 $(dW)$<br>\n",
    "- $\\beta_2$: 0.999 $(dW^2)$\n",
    "- $\\epsilon$: $10^{-8}$\n",
    "\n",
    "### Learning rate decay\n",
    "1 epoch = 1 pass through the data; with this:<br>\n",
    "$\\alpha = \\cfrac{1}{1+(\\text{decay rate} \\cdot \\text{# epoch})}$<br>\n",
    "With this formula you have to tune 2 hyperparameters (alpha and decay rate).<br>\n",
    "\n",
    "**Other methods:**<br>\n",
    "- $\\alpha = 0.95^{\\text{#epoch}} \\cdot \\alpha$: Exponential decay.\n",
    "- $\\alpha = \\cfrac{k}{\\sqrt{\\text{#epoch}}}\\cdot \\alpha$ or $\\cfrac{k}{\\sqrt{t}}\\cdot \\alpha$\n",
    "- Discrete decay.\n",
    "- Manual decay."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning, Batch Normalization and Programming Frameworks\n",
    "### Hyperparamter tuning\n",
    "\n",
    "Until now, we know the following hyperparamters.\n",
    "- $\\alpha$: Learning Rate.\n",
    "- $\\beta$: Momentum.\n",
    "- $\\beta_1, \\beta_2, \\epsilon$ : Hyperparameters for Adam optimization.\n",
    "- Number of layers.\n",
    "- Number of hidden units.\n",
    "- Learning rate decay.\n",
    "- Mini-batch size<br>\n",
    "\n",
    "**Try random values: Don't use a grid**\n",
    "\n",
    "<img src='img/img30.jpg' style=\"width:400px; height:150px\"/><br>\n",
    "\n",
    "#### Using an appropiate scale to pick hyperparameters\n",
    "\n",
    "For certain hyperparameters it is ok to just use random values in a linear scale. For example the number of hidden layers in the network.<br>\n",
    "For other hyperparameters you have to consider using a different scale. For example while tuning the learning rate, if you suspect that the optimum value is near 0.0001 and between 0.0001 and 1 you should try a log scale.\n",
    "- Learning rate sampling in a random linear scale:\n",
    "\n",
    "<img src='img/img31.jpg' style=\"width:350px; height:250px\"/><br>\n",
    "- Learning rate sampling in a random logaritmical scale:\n",
    "    - $\\alpha \\rightarrow \\text{ranges between } [0.0001,1]$<br>\n",
    "    Set $\\text{random} = \\text{np.random.rand(n)}$, $\\alpha = 10^{\\text{random}}$.<br>\n",
    "    <img src='img/img32.jpg' style=\"width:350px; height:250px\"/><br>\n",
    "- Beta sampling for exponentially weighted averages:\n",
    "    - $\\beta = 0.9 \\rightarrow \\text{sampling the last 10 values}$<br>\n",
    "    $\\beta = 0.999 \\rightarrow \\text{sampling the last 1000 values}$, So:<br>\n",
    "    $1-\\beta \\rightarrow \\text{ranges between } [0.1,0.001]$<br>\n",
    "    Set $\\text{random} = \\text{np.random.uniform(-3,-1,n)}$, $\\beta = 1 - 10^{\\text{random}}$.<br>\n",
    "    <img src='img/img33.jpg' style=\"width:350px; height:250px\"/><br>\n",
    "    \n",
    "**For tunning the hyperparamters we can babysit a model, changing its hyperparameters while it runs or by training many models in parallel.(Pandas vs Caviar)**\n",
    "\n",
    "### Batch normalization\n",
    "#### Normalizing activations in a network\n",
    "To speed up the optimization process, normalizing the inputs of the model is a common practice. For deep learning it is possible to normalize the activation nodes in the network.<br>\n",
    "Given some intermediate values in a NN we are going to normalize $Z^{(1)},Z^{(2)},...,Z^{(m)}$.\n",
    "- $\\mu = \\frac{1}{m} \\sum_{i=1}^{m}Z^{(i)}$\n",
    "- $\\sigma^2 = \\frac{1}{m} \\sum_{i=1}^{m}(Z^{(i)} - \\mu)^2$\n",
    "- $Z^{(i)}_{\\text{norm}} = \\cfrac{Z^{(i)} - \\mu}{\\sqrt{\\sigma^2 + \\epsilon}}$\n",
    "- $\\tilde{Z}^{(i)} = \\gamma Z^{(i)}_{\\text{norm}} + \\beta$<br>\n",
    "$\\beta \\text{ and } \\gamma$ are learnable parameters that allows to set the mean of Z.\n",
    "\n",
    "#### Fitting Batch Normalization into a neural network\n",
    "For the following neural network:<br>\n",
    "\n",
    "<img src='img/img34.jpg' style=\"width:420px; height:140px\"/><br>\n",
    "\n",
    "$X \\xrightarrow{W^{[1]},b^{[1]}} Z^{[1]} \\xrightarrow{\\beta^{[1]},\\gamma^{[1]}} \\tilde{Z}^{[1]} \\xrightarrow{g^{[1]}} A^{[1]} \\xrightarrow{W^{[2]},b^{[2]}} Z^{[2]} \\xrightarrow{\\beta^{[2]},\\gamma^{[2]}} \\tilde{Z}^{[2]} \\xrightarrow{g^{[2]}} A^{[2]} ...$<br>\n",
    "\n",
    "Parameters:\n",
    "- $W^{[1]},b^{[1]},W^{[2]},b^{[2]},...,W^{[L]},b^{[L]}$\n",
    "- $\\beta^{[1]},\\gamma^{[1]},\\beta^{[2]},\\gamma^{[2]},...,\\beta^{[L]},\\gamma^{[L]}$\n",
    "\n",
    "#### Why does Batch normalization works\n",
    "When you apply batch normalization, the values of the intermediate layers don't chage that much and you avoid the *Covariance shift*, this is because the mean and variance of the values in the network get estandarized.<br>\n",
    "Batch normalization also has a regularization effect. While normalizing the mini-batch, you add some noise to the values of Z also adding a slight regularization effect as a side effect.\n",
    "\n",
    "#### Batch Norm at test time\n",
    "To compute the mean and variance of the to forward propagate at test time, you have to store a exponentially weighted average of them at train time across mini-batches.\n",
    "\n",
    "### Muliti-class classification\n",
    "#### Softmax Regression\n",
    "\n",
    "For multi-class classification we need the final layer to output values representing the probability of each class.\n",
    "\n",
    "<img src='img/img35.jpg' style=\"width:480px; height:140px\"/><br>\n",
    "\n",
    "In this final layer we'll compute:<br>\n",
    "1. Compute the linear part of the layer: $Z^{[l]} = W^{[L]}a^{[L-1]} + b^{[L]}$\n",
    "2. Compute the activation function:\n",
    "    - $t=e^{(Z^{[L]})}$\n",
    "    - $a^{[L]} = \\cfrac{t}{\\sum_{i=1}^{n}t_i}\\rightarrow a_i^{[L]} = \\cfrac{t_i}{\\sum_{i=1}^{n}t_i}$\n",
    "    \n",
    "For example:\n",
    "- $Z^{[L]} = \\begin{bmatrix} 5\\\\2\\\\-1\\\\4 \\end{bmatrix}$\n",
    "- $t = \\begin{bmatrix} e^5\\\\e^2\\\\e^{-1}\\\\e^3 \\end{bmatrix} = \\begin{bmatrix} 148.4\\\\7.4\\\\0.4\\\\20.1 \\end{bmatrix}$\n",
    "- $\\sum_{i=1}^n t_i = 176.3$\n",
    "- $a^{[L]} = \\cfrac{t}{176.3} = \\begin{bmatrix} 0.842\\\\0.042\\\\0.002\\\\0.114 \\end{bmatrix}$\n",
    "\n",
    "This method works with simple linear regressions with no hidden layers, here are some examples:\n",
    "\n",
    "<img src='img/img36.jpg' style=\"width:450px; height:240px\"/><br>\n",
    "\n",
    "#### Training a softmax classifier\n",
    "- Loss function $\\rightarrow L(\\hat{y},y)=-\\sum_{i=1}^{c} y_i log\\hat{y}_i$\n",
    "\n",
    "- Cost of the entire set: $\\frac{1}{m} \\sum_{i=1}^mL(\\hat{y}^{(i)},y^{(i)})$\n",
    "\n",
    "- Gradient descent with softmax:\n",
    "    - Backprop: $\\cfrac{\\partial J}{\\partial Z^{[L]}} = dZ^{[L]} = \\hat{y}-y$\n",
    "\n",
    "### Tensorflow\n",
    "**Implementation to find the minimum of**$J(w)=w^2-10w+25$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Manuel\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\compat\\v2_compat.py:65: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "# Importaciones;\n",
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# Definición de variables;\n",
    "coefficients = np.array([[1],[-10],[25]])\n",
    "w = tf.Variable(0,dtype=tf.float32)\n",
    "x = tf.placeholder(tf.float32,[3,1])\n",
    "# cost = w**2 - 10*w + 25\n",
    "cost = x[0][0]*w**2 + x[1][0]*w + x[2][0]\n",
    "train = tf.train.GradientDescentOptimizer(0.01).minimize(cost)\n",
    "init = tf.global_variables_initializer()\n",
    "session = tf.Session()\n",
    "session.run(init)\n",
    "print(session.run(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.099999994\n"
     ]
    }
   ],
   "source": [
    "session.run(train, feed_dict={x:coefficients})\n",
    "print(session.run(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.999988\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    session.run(train, feed_dict={x:coefficients})\n",
    "print(session.run(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Course 3 - Structuring Machine Learning Projects\n",
    "## Introduction\n",
    "In this part of the specialization we are going to check at a series of ML strategies to analize a problem, this to choose the most promizing way to optimize the model.\n",
    "### Ortogonalization\n",
    "This is the concept of designing the tuners of a ML model to just change one thing at a time so that it is easier to tune.<br>\n",
    "\n",
    "**Chain of assumptions**<br>\n",
    "- Fit training set well on cost function. (Tune with: Bigger network, Adam)\n",
    "- Fit dev set well on cost function. (Tune with: Regularization, bigger train set)\n",
    "- Fit test set well on cost function. (Tune with: Bigger dev set)\n",
    "- Performs well in the real world. (Tune with: Go back and change the dev set or the cost function)\n",
    "\n",
    "## Setting up your goal\n",
    "### Single number evaluation metric\n",
    "Rather than using multiple metrics for a model, you should pick one to easily evaluate the performance of multiple iterations of the model.\n",
    "\n",
    "<img src='img/img37.jpg' style=\"width:450px; height:150px\"/><br>\n",
    "For example in this case where we have:\n",
    "- Presicion:$\\cfrac{\\text{True Positive}}{\\text{True positive }+\\text{ False Positive}}$; % correct labels of all true labeled examples.\n",
    "- Recall: $\\cfrac{\\text{True Positive}}{\\text{True positive }+\\text{ False Negatives}}$ % of examples of that are correctly labeled.<br>\n",
    "\n",
    "Instead of using this you should use what is called:\n",
    "- $F_1\\text{Score} = \\cfrac{2 \\cdot PR}{P+R}$\n",
    "\n",
    "### Satisficing and optimizing metric\n",
    "Here is another example:<br>\n",
    "\n",
    "<img src='img/img38.jpg' style=\"width:359px; height:100px\"/><br>\n",
    "\n",
    "In this case, both metrics are in different scales so we can say that.\n",
    "- Accuracy is a Optimizing metric. We want to maximize it.\n",
    "- Running time is a Satisficing metric. There is a min treshold.\n",
    "\n",
    "### Train/dev/test distributions\n",
    "\n",
    "We'll focus on to how to structure our development set (or holdout cross validation set) and test sets. Remember that the dev and test set must come from the same distribution.\n",
    "In the modern era of deep learning, test and dev set can be around 1% given the fact that DL datasets are big (around 1MM).<br>\n",
    "Consider that the metric could change depending on the business needs, let's say that a model's metric throws a high score but it lets through pornography. This is unacceptable, so one option is to raise the cost of a pornographic error.<br>\n",
    "In general, if doing well on your metric + dev/test set does not correspond to doing well on your application, change your metric and/or dev/test set.\n",
    "\n",
    "### Improving your model performance\n",
    "Human level performance can work as a proxy to estimate Bayes Error (minimum possible error) for congnition problems (Computer vision, speech recognition, NPL, etc.)<br>\n",
    "\n",
    "Human level<br>\n",
    "$\\Bigg\\updownarrow\\text{Avoidable bias}$<br>\n",
    "Training error<br>\n",
    "$\\Bigg\\updownarrow\\text{Variance}$<br>\n",
    "Dev Error\n",
    "\n",
    "**Avoidable bias:**\n",
    "- Train bigger model.\n",
    "- Train longer/better optimization algorithms (momentum, RMSprop, ADAM).\n",
    "- NN architecture/hyperparameters search.\n",
    "\n",
    "**Variance:**\n",
    "- More data.\n",
    "- Regularization ($L_2$, dropout, data augmentation).\n",
    "- NN Architecture/Hyperparameter search.\n",
    "\n",
    "## Error Analysis\n",
    "### Carrying out error analysis\n",
    "It consists in manually looking at missclassified examples on the dev set searching for patterns in them. One way to evaluate multiple ideas for why the model is misclassifing things is to build the following table.<br>\n",
    "\n",
    "|Image|Idea 1|Idea 2|Idea 3|Comments|\n",
    "|:-:|:-:|:-:|:-:|:-:|\n",
    "|1|ok|-|-|...|\n",
    "|2|-|-|ok|...|\n",
    "|3|-|ok|-|...|\n",
    "|...|...|...|...|...|\n",
    "|% of total|8%|43%|61%|...|\n",
    "\n",
    "### Cleaning up incorrectly labeled data\n",
    "- Apply the same process to your dev and test sets to make sure they continue to come from the same distribution.\n",
    "- Consider examining examples your algorithm got right as well as ones it got wrong.\n",
    "- Train and deb/test data may now come from slightlt different distrtibutions\n",
    "\n",
    "\n",
    "## Mismatched training and dev/test sets\n",
    "### Training and testing on different distributions\n",
    "For real world deep learning applications, data can come from different distributions. For example in an online classifier you can have high quality images to train on (200,000) but you also have low resolution ones (10,000). With this we have 2 options:<br>\n",
    "\n",
    "1. Option 1: Shuffle all images and build a train (205,000), dev (2,500) and test (2,500) set.\n",
    "2. Option 2: Build your train (200,000 HQ and 5,000 Low Quality), dev (2,500 LQ) and test (2,500 LQ) set.\n",
    "\n",
    "The second option is the optimal one because the actual application is going to process more LQ than HQ images. The only thing to keep in consideration is that the dev/test set must come from the same distribution.\n",
    "\n",
    "### Bias and Variance with mismatched data distributions\n",
    "When the training data and dev/test data come from different distributions, it is hard to tell if the algorithm is doing ok or not because our metric is evaluating in maybe a harder distrubution. To handle this we can create a new set for testing our model:\n",
    "- Training-dev set: Same distribution as training set, but not used for training.\n",
    "\n",
    "Human level<br>\n",
    "$\\Bigg\\updownarrow\\text{Avoidable bias}$<br>\n",
    "Training set error<br>\n",
    "$\\Bigg\\updownarrow\\text{Variance}$<br>\n",
    "Training-dev set error<br>\n",
    "$\\Bigg\\updownarrow\\text{Data mismatch}$<br>\n",
    "Dev set error<br>\n",
    "$\\Bigg\\updownarrow\\text{Degree of overfitting to dev set}$<br>\n",
    "Test set error<br>\n",
    "\n",
    "### Addressing data mismatch\n",
    "- Carry out manual error analysis to try to understand difference between training and dev/test sets.\n",
    "- Make training data more similar, or collect more data similar to dev/test sets.\n",
    "\n",
    "## Learning from multiple tasks\n",
    "### Transfer Learning\n",
    "One of the most powerful ideas in deep learning is that sometimes you can take knowledge the neural network has learned from one task and apply that knowledge to a separate task. This is called Transfer Learning.\n",
    "The first step is to train a NN in a certain task and then delete the last output layer and it's weights to create a new layer for the new tas with new randomly inintialized weights.\n",
    "\n",
    "<img src='img/img39.jpg' style=\"width:459px; height:140px\"/><br>\n",
    "\n",
    "Transfer Learning makes sense when:\n",
    "- Task A and B have the same input x.\n",
    "- You have a lot more data for Task A than Task B.\n",
    "- Low level features from A could be helpful for learning B.\n",
    "\n",
    "### Multi-task learning\n",
    "\n",
    "In Multi-task learning you start simultaneously, trying to have one neural network do several things at the same time. And then each of those tasks helps hopefully all of the other task.\n",
    "\n",
    "<img src='img/img40.jpg' style=\"width:459px; height:140px\"/><br>\n",
    "\n",
    "Loss: $\\frac{1}{m} \\sum^m_{i=1}\\sum^4_{j=1} L(\\hat{y}^{(i)}_j,y^{(i)}_j)$\n",
    "\n",
    "Muti-task learning makes sense when:\n",
    "- Trainning on a set of tasks that could benefit from having lower level features.\n",
    "- Usually, amount of data you have for each task is quite similar.\n",
    "- Can train a big enough neural network to do well on all the tasks.\n",
    "\n",
    "## End to end deep learning\n",
    "End to end Deep Learning takes multiple states of processing of a learning system and replaces them with usually just a single neural network. For example:<br>\n",
    "\n",
    "**Speech recognintion example**<br>\n",
    "\n",
    "- Normal way:<br>\n",
    "$\\text{audio}\\xrightarrow{\\text{mscc}}\\text{features}\\xrightarrow{\\text{ml}}phonemes\\rightarrow\\text{words}\\rightarrow\\text{transcript} $<br>\n",
    "\n",
    "- End to end Deep Learning:<br>\n",
    "$\\text{audio} \\longrightarrow \\text{transcript}$\n",
    "\n",
    "**Pros**\n",
    "- Lets the data speak.\n",
    "- Less hand-designing of components needed.\n",
    "\n",
    "**Cons:**\n",
    "- May need large amount of data.\n",
    "- Excludes potentially useful hand-designed components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Course 4 - Convolutional Neural Network\n",
    "## Foundations of Convolutional Neural Networks\n",
    "### Computer Vision\n",
    "Computer Vision is one of the areas that's been advancing rapidly thanks to deep learning, you can also take ideas from CV and apply them on speech recognition and other tasks. Here are som application examples:\n",
    "\n",
    "<img src='img/img41.jpg' style=\"width:720px; height:380px\"/><br>\n",
    "\n",
    "When you apply DL on images let say a 64x64x3 picture you end up with a 12,288 parameter first layer, and with a large image of 1000x1000x3 you end up with a 3 million parameter first layer. For the later let's say there are 1000 hidden units, with this you end up training on 3 billion parameters. With this many paramters it's difficult to get enough data to prevent a NN from overfitting and the computational and memory requirements are extremely high. To train on large images it's better to implement the convolution operation.\n",
    "\n",
    "### Edge Detection Example\n",
    "\n",
    "The earlier layers of a NN might detect edges and the later layers might detect larger objects like people's faces. Here we'll take a look at how to detect edges.\n",
    "<br>\n",
    "\n",
    "**Vertical Edge Detector:**\n",
    "\n",
    "$\\begin{bmatrix}\n",
    "3 & 0 & 1 & 2 & 7 & 4 \\\\\n",
    "1 & 5 & 8 & 9 & 3 & 1 \\\\\n",
    "2 & 7 & 2 & 5 & 1 & 3 \\\\\n",
    "0 & 1 & 3 & 1 & 7 & 8 \\\\\n",
    "2 & 4 & 5 & 2 & 3 & 9 \\\\\n",
    "\\end{bmatrix}\n",
    "* \\begin{bmatrix}\n",
    "1 & 0 & -1 \\\\\n",
    "1 & 0 & -1 \\\\\n",
    "1 & 0 & -1 \\\\\n",
    "\\end{bmatrix}\n",
    "= \\begin{bmatrix}\n",
    "-5 & -4 & 0 & 8 \\\\\n",
    "-10 & -2 & 2 & 3 \\\\\n",
    "0 & -2 & -4 & -7 \\\\\n",
    "-3 & -2 & -3 & -16 \\\\\n",
    "\\end{bmatrix}$\n",
    "\n",
    "Here we are appllying the convolution ($*$) operation, which multilplies the filter layer in every 3x3 space, for this example, of the 6x6 image ending up in a 4x4 image. Here is a simpler example:<br>\n",
    "\n",
    "$\\begin{bmatrix}\n",
    "10 & 10 & 10 & 0 & 0 & 0 \\\\\n",
    "10 & 10 & 10 & 0 & 0 & 0 \\\\\n",
    "10 & 10 & 10 & 0 & 0 & 0 \\\\\n",
    "10 & 10 & 10 & 0 & 0 & 0 \\\\\n",
    "10 & 10 & 10 & 0 & 0 & 0 \\\\\n",
    "\\end{bmatrix}\n",
    "* \\begin{bmatrix}\n",
    "1 & 0 & -1 \\\\\n",
    "1 & 0 & -1 \\\\\n",
    "1 & 0 & -1 \\\\\n",
    "\\end{bmatrix}\n",
    "= \\begin{bmatrix}\n",
    "0 & 30 & 30 & 0 \\\\\n",
    "0 & 30 & 30 & 0 \\\\\n",
    "0 & 30 & 30 & 0 \\\\\n",
    "0 & 30 & 30 & 0 \\\\\n",
    "\\end{bmatrix}$\n",
    "\n",
    "<img src='img/img42.jpg' style=\"width:300px; height:100px\"/><br>\n",
    "\n",
    "### More Edge Detection\n",
    "\n",
    "Here we'll see the difference between positive and negative edges, that is, the difference between light to dark vs. dark to light transitions.\n",
    "\n",
    "<img src='img/img43.jpg' style=\"width:600px; height:338px\"/><br>\n",
    "\n",
    "**Vertical filter**<br>\n",
    "\n",
    "$\\begin{bmatrix}\n",
    "1 & 0 & -1 \\\\\n",
    "1 & 0 & -1 \\\\\n",
    "1 & 0 & -1 \\\\\n",
    "\\end{bmatrix}$<br>\n",
    "\n",
    "**Horizontal filter**<br>\n",
    "\n",
    "$\\begin{bmatrix}\n",
    "1 & 1 & 1 \\\\\n",
    "0 & 0 & 0 \\\\\n",
    "-1 & -1 & -1 \\\\\n",
    "\\end{bmatrix}$<br>\n",
    "\n",
    "**Sobel Filter**\n",
    "\n",
    "$\\begin{bmatrix}\n",
    "1 & 0 & -1 \\\\\n",
    "2 & 0 & -2 \\\\8\n",
    "1 & 0 & -1 \\\\\n",
    "\\end{bmatrix}$<br>\n",
    "\n",
    "**Scharr filter**\n",
    "\n",
    "$\\begin{bmatrix}\n",
    "3 & 0 & -3 \\\\\n",
    "10 & 0 & -10 \\\\\n",
    "3 & 0 & -3 \\\\\n",
    "\\end{bmatrix}$<br>\n",
    "\n",
    "**Deep learning filter**\n",
    "\n",
    "$\\begin{bmatrix}\n",
    "w_1 & w_2 & w_3 \\\\\n",
    "w_4 & w_5 & w_6 \\\\\n",
    "w_7 & w_8 & w_9 \\\\\n",
    "\\end{bmatrix}$<br>\n",
    "\n",
    "### Padding\n",
    "\n",
    "The dimension of the output of a convolution operation is:<br>\n",
    "\n",
    "$(n-f+1,n-f+1)$<br>\n",
    "\n",
    "Where:\n",
    "- n: dim of an image $(n,n)$\n",
    "- f: dim of the filter $(f,f)$\n",
    "\n",
    "Given this, every time that we do a convolution operation on an image, it will shrink and also we loose information from the edges of the image. The solution is to \"pad\" the image (by convention we use 0s) and with this we avoid shrinking the image. When we pad an image the new dimesions of the output are:<br>\n",
    "\n",
    "$(n+2p-f+1,n+2p-f+1)$<br>\n",
    "\n",
    "**Valid convolution**: Means no padding.<br>\n",
    "**Same**: Pad so that output size is the same as the input size.  $(p=\\frac{f-1}{2})$<br>\n",
    "\n",
    "### Strided Convolutions\n",
    "\n",
    "Strided convolution is another building block for convolutional NN. Let's say that we want to convolve this 7x7 image with a 3x3 filter, except that instead of doing it in the usual way, we are going to do it with a stride of two.\n",
    "\n",
    "$\\begin{bmatrix}\n",
    "2 & 3 & 7 & 4 & 6 & 2 & 9 \\\\\n",
    "6 & 6 & 9 & 8 & 7 & 4 & 3 \\\\\n",
    "3 & 4 & 8 & 3 & 8 & 9 & 7 \\\\\n",
    "7 & 8 & 3 & 6 & 6 & 3 & 4 \\\\\n",
    "4 & 2 & 1 & 8 & 3 & 4 & 6 \\\\\n",
    "3 & 2 & 4 & 1 & 9 & 8 & 3 \\\\\n",
    "0 & 1 & 3 & 9 & 2 & 1 & 4 \\\\\n",
    "\\end{bmatrix}\n",
    "* \\begin{bmatrix}\n",
    "3 & 4 & 4 \\\\\n",
    "1 & 0 & 2 \\\\\n",
    "-1 & 0 & 3 \\\\\n",
    "\\end{bmatrix}\n",
    "= \\begin{bmatrix}\n",
    "91 & 100 & 83 \\\\\n",
    "69 & 91 & 127 \\\\\n",
    "44 & 72 & 74 \\\\\n",
    "\\end{bmatrix}$\n",
    "\n",
    "With this:\n",
    "\n",
    "- $(n,n) * (f,f) =\\Bigg\\lfloor\\Bigg(\\cfrac{n+2p-f}{s}+1,\\cfrac{n+2p-f}{s}+1\\bigg)\\Bigg\\rfloor$\n",
    "\n",
    "- Where $ n = \\text{image size}, f = \\text{filter size}, s = \\text{stride step}$.\n",
    "\n",
    "**Technical note on cross-correlation vs. convolution**<br>\n",
    "In math text book the convolution operation that we are doing, flips in both axes the filter before convolving. The actual operation that we are doing is named cross-correlation but for practical reasons and convention in the deep learning literature we are going to call it convolution.<br>\n",
    "The objective of flipping the filter before convolving is to obtain the distributive property in the operation: $(A*B)*C = A*(B*C)$\n",
    "\n",
    "### Convolutions Over Volume\n",
    "\n",
    "Here we'll see how to implement convolutions over three dimensional volumes. Let start with an eample:\n",
    "\n",
    "<img src='img/img44.jpg' style=\"width:600px; height:200px\"/><br>\n",
    "\n",
    "Here the entire volume of the filter will convolve over the 3 channel picture, but the result will be a two dimensional matrix. In the process of learning you can use multiple filters for the same image and learn their values at the same time so that they detect different specific characteristics of the picture.<br>\n",
    "**Dimensions:**\n",
    "$(n,n,n_c) * (f,f,n_c) = (n-f+1,n-f+1,n_f)$\n",
    "\n",
    "### One Layer of a Convolutional Network\n",
    "\n",
    "To build one layer of a convolutional NN, you have to do the following.\n",
    "\n",
    "<img src='img/img45.jpg' style=\"width:800px; height:200px\"/><br>\n",
    "\n",
    "In this example we are using 2 filters, which is why we end up with our output 4 x 4 x 2. But if we, for example, instead of 2 we had 10, then we would have end up with a 4 x 4 x 10 dimensional output volume.<br>\n",
    "\n",
    "**Summary of notation**<br>\n",
    "\n",
    "- $f^{[l]}=\\text{filter size}$\n",
    "- $p^{[l]}=\\text{padding}$\n",
    "- $s^{[l]}=\\text{stride}$\n",
    "- $n_C^{[l]}=\\text{number of filters}$\n",
    "- $\\text{Each filter is: }(f^{[l]},f^{[l]},n_C^{[l-1]})$\n",
    "- $\\text{Input: } (n_H^{[l-1]},n_W^{[l-1]},n_C^{[l-1]})$\n",
    "\n",
    "- $\\text{Relation between input and output: }(n_H^{[l]},n_W^{[l]}) = \\Bigg\\lfloor \\Bigg( \\cfrac{n_H^{[l-1]}+2p^{[l]}-f^{[l]}}{s^{[l]}} + 1,\\cfrac{n_W^{[l-1]}+2p^{[l]}-f^{[l]}}{s^{[l]}}+1\\bigg)\\Bigg\\rfloor$\n",
    "- $\\text{Output: }(n_H^{[l]},n_W^{[l]},n_C^{[l]})$\n",
    "- $\\text{Activations: }a^{[l]}\\rightarrow (n_H^{[l]},n_W^{[l]},n_C^{[l]})$\n",
    "- $\\text{Vectorized activations: }A^{[l]}\\rightarrow (m,n_H^{[l]},n_W^{[l]},n_C^{[l]})$\n",
    "- $\\text{Weights: }(f^{[l]},f^{[l]},n_C^{[l-1]},n_f^{[l]})$\n",
    "- $\\text{Bias: }(1,1,1,n_C^{[l]})$\n",
    "\n",
    "### Simple Convolutional Network\n",
    "\n",
    "Now let's go through an exampleof a deep CNN. Let's say that we wanto to do image classification or image recognition.\n",
    "\n",
    "<img src='img/img46.jpg' style=\"width:600px; height:400px\"/><br>\n",
    "\n",
    "**Types of layer in a convolutional network:**\n",
    "- Convolution\n",
    "- Pooling\n",
    "- Fully connected\n",
    "\n",
    "### Pooling Layers\n",
    "\n",
    "Other tha convolutional layers, CNN use pooling layers to reduce the size of the representation to speed the computation, as well as make some of the features that detects a bit more robust. For example:\n",
    "\n",
    "$\\begin{bmatrix}\n",
    "1 & 3 & 2 & 1 \\\\\n",
    "2 & 9 & 1 & 1 \\\\\n",
    "1 & 3 & 2 & 3 \\\\\n",
    "5 & 6 & 1 & 2 \\\\\n",
    "\\end{bmatrix}\n",
    "\\rightarrow\n",
    "\\begin{bmatrix}\n",
    "9 & 2 \\\\\n",
    "6 & 3 \\\\\n",
    "\\end{bmatrix}$\n",
    "\n",
    "This is like having a $f=2$ and $s=2$. In max pooling there is nothing to learn by optimization, it is a fixed parametric operation. Here is another example.\n",
    "\n",
    "$\\begin{bmatrix}\n",
    "1 & 3 & 2 & 1 & 3\\\\\n",
    "2 & 9 & 1 & 1 & 5\\\\\n",
    "1 & 3 & 2 & 3 & 2\\\\\n",
    "8 & 3 & 5 & 1 & 0\\\\\n",
    "5 & 6 & 1 & 2 & 9\\\\\n",
    "\\end{bmatrix}\n",
    "\\rightarrow\n",
    "\\begin{bmatrix}\n",
    "9 & 9 & 5\\\\\n",
    "9 & 9 & 5\\\\\n",
    "8 & 6 & 9\\\\\n",
    "\\end{bmatrix}$\n",
    "\n",
    "$f=3, s=1$\n",
    "\n",
    "There is another type of pooling that is not used that often, Average Pooling instead of taking the maximum value in the filter, takes the average value.\n",
    "\n",
    "### CNN Example\n",
    "\n",
    "Let's look at this final example:\n",
    "\n",
    "<img src='img/img47.jpg' style=\"width:600px; height:400px\"/><br>\n",
    "\n",
    "The last 3 layers are Fully Connected layers, they work in the same way as in regular Neural Networks. Here are the properties of the previous example:\n",
    "\n",
    "**Corregir cuadro**\n",
    "\n",
    "<img src='img/img48.jpg' style=\"width:600px; height:250px\"/><br>\n",
    "\n",
    "### Why Convolutions?\n",
    "\n",
    "- **Parameter Sharing:** A feature detector (such as a vertical edge detector) that's useful in one part image is probably useful in another part of the image.\n",
    "\n",
    "- **Sparsity of connections:** In each layer, each output value depends only on a small number of inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep convolutional models: Case studies\n",
    "\n",
    "We're looking at some case studies because one characteristic of neural networks is that can you transfer the architecture of one constructed for a certain task to do another task and have good results. Here are some examples of NN architectures:\n",
    "\n",
    "- LeNet-5\n",
    "- AlexNet\n",
    "- VGG\n",
    "- ResNet\n",
    "- Inception NN\n",
    "\n",
    "### Classic Networks\n",
    "**LeNet-5**<br>\n",
    "<img src='img/img49.jpg' style=\"width:500px; height:170px\"/><br><br>\n",
    "\n",
    "\n",
    "**AlexNet**<br>\n",
    "<img src='img/img50.jpg' style=\"width:500px; height:200px\"/><br><br>\n",
    "\n",
    "\n",
    "**VGG-16**<br>\n",
    "<img src='img/img51.jpg' style=\"width:500px; height:250px\"/><br><br>\n",
    "\n",
    "### ResNets\n",
    "\n",
    "Residual Networks consists in skip connections in the NN which allows to take the activation from one layer and suddenly feed it to another layer even much deeper in the nerural network. This enables to train very deep networks, sometimes over 100 layers.<br>\n",
    "\n",
    "- Main path:\n",
    "    - $a^{[l]} \\rightarrow \\text{Linear} \\rightarrow \\text{ReLU} \\rightarrow a^{[l+1]} \\rightarrow \\text{ReLU} \\rightarrow a^{[l+2]}$<br>\n",
    "    - $z^{[l+1]} = W^{[l+1]}a^{[l]} + b^{[l+1]} \\rightarrow a^{[l+1]} = g(z^{[l+1]}) \\rightarrow z^{[l+2]} = W^{[l+2]}a^{[l+1]} + b^{[l+2]} \\rightarrow a^{[l+2]} = g(z^{[l+2]})$<br>\n",
    "\n",
    "\n",
    "- Residual net: \n",
    "    - $z^{[l+1]} = W^{[l+1]}a^{[l]} + b^{[l+1]} \\rightarrow a^{[l+1]} = g(z^{[l+1]}) \\rightarrow z^{[l+2]} = W^{[l+2]}a^{[l+1]} + b^{[l+2]} \\rightarrow a^{[l+2]} = g(z^{[l+2]} + a^{[l]})$\n",
    "    \n",
    "In practice, when you train deep networks, the optimization algorithm gets a bigger training error than in shallower neural networks. What ResNets do, enables the training error to go down for deep networks:\n",
    "\n",
    "<img src='img/img52.jpg' style=\"width:500px; height:350px\"/><br><br>\n",
    "\n",
    "#### Why ResNets Work\n",
    "\n",
    "If we train our network deeper it can hurt our ability to do well on the training set. We'll use ResNets to avoid this problem, for example:\n",
    "\n",
    "- Regular NN: $x \\rightarrow \\text{Big NN} \\rightarrow a^{[l]}$\n",
    "- ResNet: $x \\rightarrow \\text{Big NN} \\rightarrow a^{[l]} \\rightarrow \\text{Residual Block} \\rightarrow a^{[l + 2]}$\n",
    "\n",
    "Let's say we are using a ReLU activation function so $a>0$.\n",
    "\n",
    "- $a^{[l + 2]} = g(z^{[l+2]} + a^{[l]})$\n",
    "- $a^{[l + 2]} = g(w^{[l+2]} a^{[l+1]} + b^{[l+2]} + a^{[l]}) = g(a^{[l]})$\n",
    "\n",
    "So if $W^{[l+1]} = 0, b^{[l+2]} = 0$ then $a^{[l+2]} = a ^{[l]}$. Identity function is easier for ResNets to learn.\n",
    "\n",
    "### Networks in Networks and 1x1 Convolutions\n",
    "What does a 1x1 convolution do?.<br>\n",
    "\n",
    "**For one channel:**<br>\n",
    "$\\begin{bmatrix}\n",
    "1 & 2 & 3 & 6 & 5 & 8 \\\\\n",
    "3 & 5 & 5 & 1 & 3 & 4 \\\\\n",
    "2 & 1 & 3 & 4 & 9 & 3 \\\\\n",
    "4 & 7 & 8 & 5 & 7 & 9 \\\\\n",
    "1 & 5 & 3 & 7 & 4 & 8 \\\\\n",
    "5 & 4 & 9 & 8 & 3 & 5 \\\\\n",
    "\\end{bmatrix}\n",
    "*\n",
    "2 = \n",
    "\\begin{bmatrix}\n",
    "2 & 4 & 6 & 12 & 10 & 16 \\\\\n",
    "6 & 10 & 10 & 2 & 6 & 8 \\\\\n",
    "4 & 2 & 6 & 8 & 18 & 6 \\\\\n",
    "8 & 14 & 16 & 10 & 14 & 18 \\\\\n",
    "2 & 10 & 6 & 14 & 8 & 16 \\\\\n",
    "10 & 8 & 18 & 16 & 6 & 10 \\\\\n",
    "\\end{bmatrix}$<br>\n",
    "\n",
    "**For multiple channels:**<br>\n",
    "\n",
    "<img src='img/img53.jpg' style=\"width:300px; height:150px\"/><br><br>\n",
    "\n",
    "So, for multiple channels 1x1 convolutions work like a fully connected network across the channels of the image.\n",
    "\n",
    "### Inception Networks\n",
    "\n",
    "In an inception layer we can choose multiple methods in the same layer (convolutions, pooling layers or other filters).\n",
    "\n",
    "<img src='img/img54.jpg' style=\"width:300px; height:150px\"/><br>\n",
    "\n",
    "The problem with this method is computational cost. For example in the following diagram, to compute the next layer you need to do $28,28,28 * 5,5,192 = 120 M.$ multiplications.\n",
    "\n",
    "<img src='img/img55.jpg' style=\"width:300px; height:150px\"/><br>\n",
    "\n",
    "To solve this we can reduce the computational cost by using a 1x1 convolution layer.<br>\n",
    "The inception module takes as input the activation of a previous layer, computes various methods of convolution or pooling and then it concatenates the output blocks. Here is a picture of an Inception Network.\n",
    "\n",
    "<img src='img/img56.jpg' style=\"width:700px; height:300px\"/><br>\n",
    "\n",
    "## Practical advices for using ConvNets\n",
    "### Using Open-Source Implementations\n",
    "Whenever you can search for open source implementations in GitHub. \n",
    "\n",
    "### Transfer Learning\n",
    "Rather than training the network from scratch, search for already trained weights to speed up your learning process. One option is to apply transfer learning and freeze some layers of the imported network to avoid training them and just train the last layers.\n",
    "\n",
    "### Data Augmentation\n",
    "For implementation of data Augmentation in large datasets, it is useful to load the data, transform it and train it in different CPU threads. Here we list some data augmentation methods:<br>\n",
    "\n",
    "**Shape transformation:**\n",
    "\n",
    "<img src='img/img57.jpg' style=\"width:500px; height:250px\"/><br>\n",
    "\n",
    "**Color shifting:**\n",
    "\n",
    "There are different ways to sample R, G or B like PCA color augmentation (This method is explained in the AlexNet paper).\n",
    "\n",
    "<img src='img/img58.jpg' style=\"width:375px; height:250px\"/><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object Detection\n",
    "### Object Localization\n",
    "In order to learn about object detection we need to learn first about object localization. In image classification we can label an image into different classes, but in localization we draw a bounding box that indicates the position of the object that we are classifing.\n",
    "\n",
    "<img src='img/img59.jpg' style=\"width:320px; height:150px\"/><br>\n",
    "\n",
    "In the terminology, the classification and localization usually has one object in a big picture to localize. In the detection problem we'll have multiple objects and classes.<br>\n",
    "\n",
    "For the classification with localization we can have our CNN to ouput some coordinates for the bounding box.<br>\n",
    "\n",
    "$y = \\begin{bmatrix} \\hat{y} \\\\ b_x \\\\ b_y \\\\ b_h \\\\ b_w \\end{bmatrix}$<br>\n",
    "\n",
    "where: \n",
    "$b_x = \\text{x coordinate of the center point of the bounding box} \\\\\n",
    "b_y = \\text{y coordinate of the center point of the bounding box} \\\\\n",
    "b_w = \\text{Width of the bounding box} \\\\\n",
    "b_h = \\text{Height of the bounding box}$<br>\n",
    "\n",
    "For this problem the Loss function will be:<br>\n",
    "\n",
    "$L(\\hat{y},y) = \\Bigg\\{ \\begin{array} \\\\ \\text{if } y = 1 & (\\hat{y}_1 - y_1)^2 + (\\hat{y}_2 - y_2)^2 + ... + (\\hat{y}_n - y_n)^2 \\\\ \\text{if } y = 0 &  (\\hat{y}_1 - y_1)^2 \\end{array}$\n",
    "\n",
    "For the classification losses you can use sigmoid functions or softmax.\n",
    "\n",
    "### Landmark Detection\n",
    "\n",
    "In the same way we can tell a NN to point out the location of a bounding box, we can train it to spot landmarks. For example, augmented reality or pose detection.\n",
    "\n",
    "### Object Detection\n",
    "\n",
    "Here we'll learn how to use a CNN to perform object detection with the sliding windows detection algorithm. <br>\n",
    "First we need to create a label training set so x and y are closely cropped examples of an object. With this training set we can train a CNN that inputs an image and then outputs zero or one.\n",
    "\n",
    "<img src='img/img60.jpg' style=\"width:380px; height:270px\"/><br>\n",
    "\n",
    "We can use this CNN to implement the sliding windows detection algorithm by sliding a windos and applying the forward prop of the CNN to detect if there is a class in each stride of the window. After that, resize the window so you can detect multiple sizes.<br>\n",
    "The disadvantage of this algorithm is the conputational cost and the problem with stride size. It works well with conventional Machine Learning methods.\n",
    "\n",
    "### Convolutional Implementation of Sliding Windows\n",
    "\n",
    "To build a convolutional implemetation of sliding windows, lets first how to convert fully connected layers into convolutional layers. For this we'll use multiple filters of the size of the final convollution\n",
    "\n",
    "**Conventional FC layer:**<br>\n",
    "\n",
    "<img src='img/img61.jpg' style=\"width:700px; height:150px\"/><br>\n",
    "\n",
    "**Convollutional FC layer:**<br>\n",
    "\n",
    "<img src='img/img62.jpg' style=\"width:700px; height:150px\"/><br>\n",
    "\n",
    "With this we can implement the following,where each number in the last layer represents a prediction for stride.\n",
    "\n",
    "<img src='img/img63.jpg' style=\"width:700px; height:150px\"/><br>\n",
    "\n",
    "### Bounding Box Predictions\n",
    "\n",
    "The previous method we still have the problem of not being able to predict accurate bounding boxes. To improve this we'll implement the YOLO (You Only Look Once) algorithm.<br>\n",
    "\n",
    "First, we'll place a grid into the image and we'll apply it to each of the grid cells.\n",
    "\n",
    "<img src='img/img64.jpg' style=\"width:300px; height:300px\"/><br>\n",
    "\n",
    "The labels for training for each grid cell we'll be: <br>\n",
    "\n",
    "$y = \\begin{bmatrix} p_c \\\\ b_x \\\\ b_y \\\\ b_h \\\\ b_w \\\\ c_1 \\\\ c_2 \\\\ c_3 \\end{bmatrix}$<br>\n",
    "\n",
    "Where:\n",
    "$p_c = \\text{Probability of there being an image in the gridcell} \\\\\n",
    "b_x = \\text{x coordinate of the center point of the bounding box} \\\\\n",
    "b_y = \\text{y coordinate of the center point of the bounding box} \\\\\n",
    "b_w = \\text{Width of the bounding box} \\\\\n",
    "b_h = \\text{Height of the bounding box} \\\\\n",
    "c_1 = \\text{Probability of classifying the picture as class 1} \\\\\n",
    "c_2 = \\text{Probability of classifying the picture as class 2} \\\\\n",
    "c_3 = \\text{Probability of classifying the picture as class 3}$<br>\n",
    "\n",
    "The algorithms assigns each detection to the gridcell containing the center of the identified object. To train this neural network we'll implement a regular ConvNet and then we should choose each layer so it maps into a $3x3x8$ for the image in the example.<br> \n",
    "To specify the bounding boxes for the gridcell well use the convention that for each gricell we'll consider its upper left corner as 0,0 coordinates. Each $b_x, b_y$ will be the relative position in the gridcell between 0 and 1.\n",
    "**READ THE PAPER**\n",
    "\n",
    "### Intersection Over Union\n",
    "\n",
    "In the object detection task we have to localize the objecy too. The intersection over union we'll help us to choose between multiple detections for the same object.<br>\n",
    "\n",
    "Intersection over Union: $\\cfrac{\\text{Size of intersetcion between detections}}{\\text{Size of union between detections}}$<br>\n",
    "\n",
    "By convention the localized object is the right one if the IoU is larger than 0.5.\n",
    "\n",
    "<img src='img/img65.jpg' style=\"width:300px; height:300px\"/><br>\n",
    "\n",
    "In general, IoU is a measure of the overlap between two bounding boxes.\n",
    "\n",
    "### Non-max Supression\n",
    "\n",
    "One of the problems with object detection is that the algorithms could detect the same object multiple times. We'll use the Non-max supression technique so we detect each object just once.<br>\n",
    "When running the YOLO algorithm we'll might end up with multiple detections for the same object, by evaluating the probability of each detection we'll supress the low prob ones so that we end up with just one detection per object. This is done by discarding any remaining box with an IoU > 0.5 with the maximum probability box in each gricell.\n",
    "For multiple classes, it is necesary to run non max suppression for each class.\n",
    "\n",
    "### Anchor Boxes\n",
    "\n",
    "In we want to detect more than one object per gridcell we need to use Anchor Boxes. First predefine some anchor boxes so that we can associate one predictio per box.\n",
    "For example, with two anchor boxes, each object in training image is assigned to a gridcell that contains object's midpoint and achor box for the grid cell with highest IoU.\n",
    "\n",
    "<img src='img/img66.jpg' style=\"width:600px; height:500px\"/><br>\n",
    "\n",
    "### YOLO Algorithm\n",
    "\n",
    "Here we'll put all previously seen methods to implement the YOLO object detection algorithm.\n",
    "\n",
    "**Training:**\n",
    "\n",
    "<img src='img/img67.jpg' style=\"width:600px; height:400px\"/><br>\n",
    "\n",
    "**Making predictions:**\n",
    "\n",
    "<img src='img/img68.jpg' style=\"width:600px; height:300px\"/><br>\n",
    "\n",
    "**Non-Max Supression:**\n",
    "\n",
    "- With two anchor boxes, we'll get 2 predicted bounding boxes.\n",
    "- Get rid of low probability predictions.\n",
    "- For each class use non-max supression to generate final predictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face Recognition\n",
    "### What is face recognition?\n",
    "**Verification:**\n",
    "- Input image, Name/ID.\n",
    "- Output whether the input image is that of the claimed person.\n",
    "\n",
    "**Recognition:**\n",
    "- Has a database of K persons.\n",
    "- Get an input image.\n",
    "- Output ID if the image is any of the K persons (or \"not recognized\")\n",
    "\n",
    "### One Shot Learning\n",
    "\n",
    "The one shot problem consists in being able to recognize a person given just one single image, or on example per person. To carry out this we need that our NN learns a \"similarity\" function:\n",
    "\n",
    "- $d(\\text{img1}, \\text{img2}) = \\text{degree of difference between images}$\n",
    "\n",
    "If two images are of the same person, we want our function to output a small number. If all the comparisons output large numbers, the image is not in the database. \n",
    "\n",
    "### Siamese Network\n",
    "\n",
    "To implement the similarity function we are going to use a Siamese Network. This consits in using a network to encode a picture as following.\n",
    "\n",
    "<img src='img/img69.jpg' style=\"width:650px; height:270px\"/><br>\n",
    "\n",
    "The comparition between the output of different images encoded via this NN is the degree of difference between images.<br>\n",
    "\n",
    "$d(x^{(1)},x^{(2)}) = ||f(x^{(1)}) - f(x^{(2)})||^{2}$\n",
    "\n",
    "To train this network we want to learn parameters so that if:<br>\n",
    "- $x^{(i)},x^{(j)} \\text{ are the same person, } ||f(x^{(1)}) - f(x^{(2)})||^{2}\\text{ is small.}$\n",
    "- $x^{(i)},x^{(j)} \\text{ are different persons, } ||f(x^{(1)}) - f(x^{(2)})||^{2}\\text{ is large.}$\n",
    "\n",
    "### Triplet Loss\n",
    "\n",
    "One way to learn the parameters for the siamese network is to define gradient descend in a triplet loss function. To do this we need an anchor (A) picture and compare it to a Positive (P) and Negative (N) examples.\n",
    "\n",
    "- We want: $d(A,P) = ||f(A) - f(P)||^{2} \\leq d(A,N) = ||f(A) - f(N)||^{2}$\n",
    "\n",
    "If we apply an optimization algorithm, the process will assign 0 to all parameters. To solve this:\n",
    "\n",
    "- $||f(A) - f(P)||^{2} - ||f(A) - f(N)||^{2}  + \\alpha \\leq 0$\n",
    "\n",
    "This alpha parameter pushes negative and positive results further away from each other.<br>\n",
    "The triplet loss function is defined on triplets of images. Given 3 images (A,P and N):\n",
    "\n",
    "- $L(A,P,N) = \\text{max}(||f(A) - f(P)||^{2} - ||f(A) - f(N)||^{2}  + \\alpha, 0)$\n",
    "\n",
    "To train this system, we need multiple pictures of the same person so we have pairs of anchor and positive images. During training, if  A,P and N are chosen randomly, $d(A,P) + \\alpha \\leq d(A,N)$ is easily satisfied (Because there is a high probability we are going to train on very different pairs of persons). To solve this problem, we need to choose triplets that are hard to train on.\n",
    "\n",
    "### Face Verification and Binary Classification\n",
    "\n",
    "Another way to learn this parameters is to take the siamese network, compute the encoding of both and feed a logistic unit.\n",
    "\n",
    "<img src='img/img70.jpg' style=\"width:650px; height:200px\"/><br>\n",
    "\n",
    "- $\\hat{y} = \\sigma (\\sum^{128}_{k=1}w_k|f(x^{(i)})_k - f(x^{(j)})| +b)$, or<br>\n",
    "- $\\hat{y} = \\sigma (\\sum^{128}_{k=1}w_k\\cfrac{(f(x^{(i)})_k - f(x^{(j)}))^2}{ f(x^{(i)})_k + f(x^{(j)})}+b)$\n",
    "\n",
    "<img src='img/img71.jpg' style=\"width:300px; height:360px\"/><br>\n",
    "\n",
    "**More on the DeepFace paper**\n",
    "\n",
    "## Neural Style Transfer\n",
    "### What is Neural Style Transfer\n",
    "\n",
    "Neural Style Transfer allows you to generate a new image but drawn in the style of other.\n",
    "\n",
    "<img src='img/img72.jpg' style=\"width:650px; height:300px\"/><br>\n",
    "\n",
    "### What are deep CNN learning?\n",
    "\n",
    "To find out what is a CNN is learning froma dataset, you should do the followin\n",
    " \n",
    "<img src='img/img73.jpg' style=\"width:600px; height:270px\"/><br>\n",
    "\n",
    "For deeper layers, this are the patches that maximize the activations:\n",
    "\n",
    "<img src='img/img74.jpg' style=\"width:600px; height:120px\"/><br>\n",
    "\n",
    "### Cost Funtion\n",
    "\n",
    "In order to implement NST, we need to define a cost function to measure how good is a generated image.\n",
    "\n",
    "**Content Cost:** $J(G) = \\alpha J_{\\text{content}}(C,G) + \\beta J_{\\text{style}}(S,G)$\n",
    "\n",
    "The weights will determine the balance between the importance of the content and style images. In order to generate the image we need to do the following:\n",
    "\n",
    "1. Initiate G randomly: $G:100,100,3$\n",
    "2. Use gradient descent to minimize $J(G)$\n",
    "\n",
    "### Content Cost Function\n",
    "\n",
    "- Say you use a hidden layer $l$ to compute content cost. $l$ should be in between the network.\n",
    "- Use a pre-trained CNN (Eg. VGG network)\n",
    "- Let $a^{[l](C)}$ and $a^{[l](G)}$ be the activation of layer $l$ on the images.\n",
    "- If $a^{[l](C)}$ and $a^{[l](G)}$ are similar, both images have similar content.\n",
    "- $J_{\\text{content}}(C,G) = ||a^{[l](C)} - a^{[l](G)}||^2$\n",
    "\n",
    "### Style Cost Function\n",
    "\n",
    "The style of an image is defined as tha correlation between activations across channels. This correlation tells us which high level texture components tend to occur or no toghether in different parts of an image.\n",
    "\n",
    "<img src='img/img75.jpg' style=\"width:600px; height:250px\"/><br>\n",
    "\n",
    "**Style Matrix:**\n",
    "\n",
    "- Let $a^{[l]}_{i,j,k} = \\text{activation at } (i,j,k). G^{[l]} \\text{is } n_c^{[l]} \\text{x} n_c^{[l]}$\n",
    "\n",
    "**Style cost function:**\n",
    "\n",
    "- $J_{\\text{style}}^{[l]}(S,G) = \\cfrac{1}{(2n_H^{[l]}n_W^{[l]}n_C^{[l]})^2}\\sum_k \\sum_{k^{\\prime}}(G_{k k^{\\prime}}^{[l](S)} - G_{k k^{\\prime}}^{[l](G)})^2$\n",
    "\n",
    "**For all layers:**\n",
    "- $J_{\\text{style}}(S,G) = \\sum_l \\lambda^{[l]} J_{\\text{style}}^{[l]}(S,G)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Course 5: Sequence Models\n",
    "## Recurrent Neural Networks\n",
    "### Why Sequence Models\n",
    "\n",
    "Models like Recurrent Neural Networks have transformed speech recognition, natural language processing and other areas. This models can be usefull for the following applications.\n",
    "\n",
    "- Speech recognition\n",
    "- Music Generation\n",
    "- Sentiment Classification\n",
    "- DNA sequence analysis\n",
    "- Machine translation\n",
    "- Video activity Recognition\n",
    "- Name entity recognition\n",
    "\n",
    "### Notation\n",
    "\n",
    "**Motivating example**<br>\n",
    "\n",
    "$x:$ Harry Potter and Hermione Granger invented a new spell.<br>\n",
    "$x: x^{<1>} x^{<2>} x^{<3>} ... x^{<9>}$; Tokenize each word<br>\n",
    "$T_x = 9$; Length of input<br>\n",
    "$y: 110110000$; Output<br>\n",
    "$y: y^{<1>} y^{<2>} y^{<3>} ... y^{<9>}$; List of Outputs (following words)<br>\n",
    "$T_y = 9$; Length of ouputs\n",
    "\n",
    "**Representing Words**<br>\n",
    "\n",
    "To represent words we must build a vocabulary based on a selected dictionary and assign a index for each word.\n",
    "\n",
    "$x:$ Harry Potter and Hermione Granger invented a new spell.<br>\n",
    "$x: x^{<1>} x^{<2>} x^{<3>} ... x^{<9>}$<br>\n",
    "\n",
    "$\\text{Dictionary} = \\text{Vocabulary: } \\begin{bmatrix} a \\\\ ... \\\\ arin \\\\ ... \\\\ and \\\\ ... \\\\ harry \\\\ ... \\\\ potter \\\\ ... \\\\ zulu \\end{bmatrix} \\begin{array} 11 \\\\ ... \\\\ 2 \\\\ ... \\\\ 367 \\\\ ... \\\\ 4075 \\\\ ... \\\\ 6830 \\\\ ... \\\\ 10000 \\end{array}$<br><br>\n",
    "\n",
    "With this you one hot encode the entire vocabulary for each word. <br>\n",
    "\n",
    "$x^{<1>}= \\begin{bmatrix} 0 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ ... \\\\ 1 \\\\ ... \\\\ 0 \\\\ 0 \\\\ 0 \\end{bmatrix}$ ; and so on for all  $x^{<n>}$ variables.\n",
    "\n",
    "### Recurrent Neural Network Model\n",
    "\n",
    "**Why not a Standard Network:**\n",
    "\n",
    "<img src='img/img76.jpg' style=\"width:400px; height:150px\"/><br>\n",
    "\n",
    "- Inputs, Outputs can be different lengths in different examples.\n",
    "- Doesn't share features learned acorss different positions of text.\n",
    "\n",
    "**Structure of a RNN:**\n",
    "\n",
    "<img src='img/img77.jpg' style=\"width:400px; height:180px\"/><br>\n",
    "\n",
    "RRNs carry information between instances of training to detect patterns across a path or sequnces of information. \n",
    "\n",
    "<img src='img/img84.jpg' style=\"width:600px; height:270px\"/><br>\n",
    "\n",
    "$a^{<0>} = \\overrightarrow{0}$<br>\n",
    "$a^{<1>} = g(W_{aa} a^{<0>} + W_{ax} x^{<1>} + b_a)$ (g = tanh/RelU)<br>\n",
    "$\\hat{y}^{<1>} = g(W_{ya} a^{<1>}  + b_y)$ (g = sigmoid)<br>\n",
    "$a^{<t>} = g(W_{aa} a^{<t-1>} + W_{ax} x^{<t>} + b_a)$<br>\n",
    "$\\hat{y}^{<t>} = g(W_{ya} a^{<t>}  + b_y)$\n",
    "\n",
    "**Simplified RNN notation:**<br>\n",
    "\n",
    "The following underlined term is the multiplication between the matrix $[W_{aa},W_{ax}]$ and the stack of the $a^{<t-1>}$ and $x^{<t>}$ matrices.\n",
    "\n",
    "$a^{<t>} = g(\\underline{W_a[a^{<t-1>} + x^{<t>}]} + b_a)$<br>\n",
    "\n",
    "$W_a[a^{<t-1>} + x^{<t>}] = W_{aa} a^{<t-1>} + W_{ax} x^{<t>}$<br>\n",
    "\n",
    "### Backpropagation through time\n",
    "\n",
    "**Loss function:**<br>\n",
    "Given the following loss function, to implemet backprop you shoud derivate across the entire computation graph. The algorithm is called Backpropagation through time.<br>\n",
    "\n",
    "$L^{<t>}(\\hat{y}^{<t>},y^{<t>})= -\\hat{y}^{<t>}log\\hat{y}^{<t>} - (1-y^{<t>}) log(1-y^{<t>})$<br>\n",
    "$L(\\hat{y},y) = \\sum_{t=1}^{T_y} L^{<t>} (y^{<t>},y^{<t>})$\n",
    "\n",
    "### Different types of RNNs\n",
    "\n",
    "<img src='img/img78.jpg' style=\"width:600px; height:300px\"/><br>\n",
    "\n",
    "### Language model and sequence generation\n",
    "\n",
    "Language modeling is one of the most basic and important tasks in natural language processing.\n",
    "\n",
    "**What is language modelling:**\n",
    "\n",
    "To implement a model that chooses between two different sentences with the same pronunciation by evaluating different probabilities. This is applied in speech recognition and machine translation. For eg.\n",
    "\n",
    "- The apple and pair salad\n",
    "- The apple and pear salad\n",
    "- $P$(The apple and pair salad) $= 3.2 * 10^{-13}$\n",
    "- $P$(The apple and pear salad) $= 5.7 * 10^{-10}$\n",
    "\n",
    "**Language modelling with an RNN:**\n",
    "\n",
    "- Training set: large corpus of english text.\n",
    "- Tokenize each sentence, considering a token for the end of a sentence \"< EOS >\".\n",
    "- If a particular word is not in the vocabulary you can tokenize it with a \"< UNK >\".\n",
    "\n",
    "**RNN model:**\n",
    "\n",
    "For the sentence: Cats average 15 hours of sleep a day.\n",
    "\n",
    "<img src='img/img79.jpg' style=\"width:600px; height:250px\"/><br>\n",
    "\n",
    "### Sampling novel sequences\n",
    "\n",
    "After you've train a sequence model, one of the ways you can informally get a sense of what is learned is to have a sample novel sequence. What you want to do is to sample what is the first word you want your model to generate, whith this you'll have a softmax distribution with chances for different words. Then you take this vector and randomly sample for the next word and pass it as input for the second position for the RNN.<br>\n",
    "Dependieng on the application, you can also build a model where the vocabulary is the abecedary and simbols. This is called a character level language model.\n",
    "\n",
    "<img src='img/img85.jpg' style=\"width:600px; height:250px\"/><br>\n",
    "\n",
    "### Gated Recurrent Unit (GRU)\n",
    "\n",
    "For long sentences, normal RNN start to have problems because of long term dependencies of the language. This is a problem called Vanishing Gradients.\n",
    "Here we'll learn about the Gated Recurrent Unit which is a modification to the RNN hidden layer that makes it much better capturing long range connections and helps a lot with the vanishing gradient problems\n",
    "\n",
    "**GRU (simplified)**\n",
    "\n",
    "- $C$: Memory cell\n",
    "- $c^{<t>} = a^{<t>}$; for now they are equal\n",
    "- $\\tilde{c}^{<t>} = tanh(W_c[c^{<t-1>}, x^{<t>}] + b_c)$; Update function.\n",
    "- Gate: $\\Gamma_u = \\sigma(W_u[c^{<t-1>}, x^{<t>}] + b_u)$; the function (0 or 1) of this gate is to decide whether to update or not the $\\tilde{c}^{<t>} value$.\n",
    "- $c^{<t>} = \\Gamma_u * \\tilde{c} + (1-\\Gamma_u) * c^{<t-1>}$\n",
    "\n",
    "**Full GRU**\n",
    "\n",
    "- $\\tilde{c}^{<t>} = tanh(W_c[\\Gamma_r * c^{<t-1>}, x^{<t>}] + b_c)$\n",
    "- $\\Gamma_u = \\sigma(W_u[c^{<t-1>}, x^{<t>}] + b_u)$\n",
    "- $\\Gamma_r = \\sigma(W_r[c^{<t-1>}, x^{<t>}] + b_r)$\n",
    "- $c^{<t>} = \\Gamma_u * \\tilde{c}^{<t>} + (1-\\Gamma_u) * c^{<t-1>}$\n",
    "\n",
    "### Long Short Term Memory\n",
    "\n",
    "This is a slightly more powerful and general version of GRU.<br>\n",
    "\n",
    "- $\\tilde{c}^{<t>} = tanh(W_c[c^{<t-1>}, x^{<t>}] + b_c)$\n",
    "- $\\Gamma_u = \\sigma(W_u[a^{<t-1>}, x^{<t>}] + b_u)$; update gate.\n",
    "- $\\Gamma_f = \\sigma(W_f[a^{<t-1>}, x^{<t>}] + b_f)$; forget gate.\n",
    "- $\\Gamma_o = \\sigma(W_o[a^{<t-1>}, x^{<t>}] + b_f)$; output gate.\n",
    "- $c^{<t>} = \\Gamma_u * \\tilde{c}^{<t>} + \\Gamma_f * c^{<t-1>}$\n",
    "- $a^{<t>} = \\Gamma_o * tanh(c^{<t>})$\n",
    "\n",
    "Here is a diagram of one layer for the RNN with LSTM.<br>\n",
    "\n",
    "<img src='img/img80.jpg' style=\"width:450px; height:330px\"/><br>\n",
    "\n",
    "This is how it looks when you connect multiple layers together.\n",
    "\n",
    "<img src='img/img81.jpg' style=\"width:1000px; height:250px\"/><br>\n",
    "\n",
    "### Bidirectional RNN\n",
    "\n",
    "For the following example, it would be necessary to have information about the future of the sequence to predict a consistent word. To solve this we'll implement a Bidirectiona RNN, this method works with LSTM or GRU blocks.\n",
    "\n",
    "- He said, \"Teddy bears are on sale!\"\n",
    "- He said, \"Teddy Roosevelt was a great President!\"\n",
    "\n",
    "This method consists in adding to the forward propagation, a second stage that goes backward with differnt $a^{<t>}$ parameters but with the same inputs in reverse order.\n",
    "\n",
    "<img src='img/img82.jpg' style=\"width:1000px; height:500px\"/><br>\n",
    "\n",
    "### Deep RNNs\n",
    "\n",
    "To implement deep RNNs we need to add layer dimensions to our chanin of layer across the temporal dimension in the following way. We can also implement Bidirectional RNN with this configurations, although they are not used that much because of computational complexity.\n",
    "\n",
    "<img src='img/img83.jpg' style=\"width:700px; height:350px\"/><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Natural Language Processing & Word Embeddings\n",
    "### Introduction to Word Embeddings\n",
    "#### Word Representation\n",
    "\n",
    "All the previous discused ideas can be applied to NPL. Here we'll see how to work with word embeddings, which is a way to represent words and allows our algorithms to understand analogies.\n",
    "\n",
    "So far we've been representing words using a one hot vector, one of the weakness is that it trats each word as an independent thing and doesn't let the algorithm to generalize. To achive this we will use a Featurized representation. For Eg.:\n",
    "\n",
    "||Man (5391)|Woman (9853)|King (4914)|Queen (7157)|Apple (456)|Orange (6257)|\n",
    "|:-:|:-:|:-:|:-:|:-:|:-:|:-:|\n",
    "|Gender|-1.00|1.00|-0.95|0.97|0.00|0.01|\n",
    "|Royal|0.01|0.02|0.93|0.95|-0.01|0.00|\n",
    "|Age|0.03|0.02|0.7|0.69|0.03|-0.02|\n",
    "|Food|0.04|0.01|0.02|0.01|0.95|0.97|\n",
    "\n",
    "Word embeddings is basically learn high dimensional feature vectores like the ones on the table that give a better representation than one hot encoded vectors. They are not as interpretable as it is representedin the table.\n",
    "\n",
    "#### Using Word Embeddings\n",
    "\n",
    "To take this representations and plug them in into an NLP model it is convenient to apply transfer learning from an already trained network from a big database (1B text corpus).\n",
    "\n",
    "1. Learn Word Embeddings from large text corpus (1-100B words). / Download pre-trained embedding online.\n",
    "2. Transfer embedding to new task with smaller  training set. (~ 100K words).\n",
    "3. Optional: Continue to finetune the word embeddings with new data.\n",
    "\n",
    "#### Properties of word embeddings\n",
    "\n",
    "If we want to identify an analogy in one of the computed vectors, we would do the following:\n",
    "\n",
    "||Man (5391)|Woman (9853)|King (4914)|Queen (7157)|\n",
    "|:-:|:-:|:-:|:-:|:-:|\n",
    "|Gender|-1.00|1.00|-0.95|0.97|\n",
    "|Royal|0.01|0.02|0.93|0.95|\n",
    "|Age|0.03|0.02|0.7|0.69|\n",
    "|Food|0.04|0.01|0.02|0.01|\n",
    "\n",
    "- Man $\\rightarrow$ Woman : $e_{\\text{man}} - e_{\\text{woman}} \\approx \\begin{bmatrix} -2 \\\\ 0 \\\\ 0 \\\\ 0 \\end{bmatrix}$\n",
    "- King $\\rightarrow$ Queen : $e_{\\text{king}} - e_{\\text{queen}} \\approx \\begin{bmatrix} -2 \\\\ 0 \\\\ 0 \\\\ 0 \\end{bmatrix}$\n",
    "\n",
    "The vector difference between two analogies is very similar. With this, if we want to find an analogy we should represent it as:\n",
    "\n",
    "- $e_{\\text{man}} - e_{\\text{woman}} \\approx e_{\\text{king}} - e_?$ \n",
    "- Find word \"W\": $\\text{argmax  } sim(e_w, e_{\\text{king}} - e_{\\text{queen}} + e_{\\text{woman}})$\n",
    "\n",
    "**Cosine Similarity**\n",
    "\n",
    "$sim(e_w, e_{\\text{king}} - e_{\\text{queen}} + e_{\\text{woman}})$<br>\n",
    "$sim(u,v) = \\cfrac{u^T v}{||u||_2||v||_2}$\n",
    "\n",
    "#### Embedding matrix\n",
    "\n",
    "When you implement an algorithm to learn a word embedding, what you end up learning is an embedding matrix.\n",
    "To extract the information about a word, we must multiply our embedding matrix with the one hot encoded vector that corresponds to tha word on our vocabulary.\n",
    "\n",
    "- E: Embedding Matrix (parameters, words)\n",
    "- O: One hot evector of the selected word.\n",
    "- $E \\dot O = \\text{embedding for word}$\n",
    "\n",
    "**NOTE:** In practice, use specialized function to look up an embedding.\n",
    "\n",
    "### Learning Word Embeddings: Word2vec & GloVe\n",
    "#### Learning Word Embeddings\n",
    "\n",
    "Here we'll learn som concrete algorithms for learning word embeddings.\n",
    "\n",
    "**Neural language model**\n",
    "\n",
    "Let's say we have the following sentence and we want to predict the last word. I want a glass of orange (?).<br>\n",
    "First we create a One hot vector for the word and multpiply it by our embedding matrix to obtain an embedding vectors.\n",
    "\n",
    "$\\begin{matrix} \n",
    "\\text{I} & O_{4343} & \\rightarrow & E & \\rightarrow & e_{4343} \\\\\n",
    "\\text{want} & O_{9665} & \\rightarrow & E & \\rightarrow & e_{9665} \\\\\n",
    "\\text{a} & O_{1} & \\rightarrow & E & \\rightarrow & e_{1} \\\\\n",
    "\\text{glass} & O_{3852} & \\rightarrow & E & \\rightarrow & e_{3852} \\\\\n",
    "\\text{of} & O_{6163} & \\rightarrow & E & \\rightarrow & e_{6163} \\\\\n",
    "\\text{orange} & O_{6257} & \\rightarrow & E & \\rightarrow & e_{6257} \\\\\n",
    "\\end{matrix}$\n",
    "\n",
    "After this we will feed all this vectors stacked to a Neural Network with an output softmax unit to predict the following word.\n",
    "\n",
    "**Other context/target pairs:**\n",
    "\n",
    "For the followint sentence: I want a glass of orange <u>juice</u> to go along with my cereal. <br>\n",
    "Context (input for the NN) could be:\n",
    "- Last 4 words.\n",
    "- 4 words on left and right.\n",
    "- Last 1 word.\n",
    "- Nearby 1 word. (Skip-gram)\n",
    "\n",
    "#### Word2Vec\n",
    "\n",
    "This algorithm is a simpler and computationally more efficient way to learn embeddings. For the following sentence:\n",
    "\n",
    "- I want a glass of orange juice to go along with my cereal.\n",
    "1. Pick a Context word randomly.\n",
    "2. Pick a randomly distanced word as a target.\n",
    "\n",
    "|Context|$\\rightarrow$|Target|\n",
    "|:-:|:-:|:-:|\n",
    "|Orange||Juice|\n",
    "|Orange||Glass|\n",
    "|Orange||my|\n",
    "\n",
    "**Model:**<br>\n",
    "With this model we want to learn a mapping from some context \"c\" to a target \"t\".<br>\n",
    "\n",
    "Vocab Size = 10,000K<br>\n",
    "\n",
    "$O_c \\rightarrow E \\rightarrow e_c \\rightarrow \\text{softmax} \\rightarrow \\hat{y}$<br>\n",
    "\n",
    "Softmax: $p(t|c) = \\cfrac{e^{\\theta^T_te_c}}{\\sum^{10,000}_{j=1} e^{\\theta^T_je_c}}$<br>\n",
    "\n",
    "$L(\\hat{y},y) = - \\sum^{10,000}_{i=1} y_i log(\\hat{y}_i)$\n",
    "\n",
    "There are computational problems with this model because when we apply softmax we are applying a loop for the entire vocabulary. One solution is to implement a Hierarchical softmax unit.\n",
    "\n",
    "#### Negative Sampling\n",
    "\n",
    "This algorithm will help us to avoid the computational problems of the softmax unit previously discussed. We are going to do the following:\n",
    "\n",
    "1. Pick a context word.\n",
    "2. Pick a target word and label it with 1 for the first row.\n",
    "3. Pick for random words from a dictionary and label them cero for the following \"k\" words.\n",
    "\n",
    "|Context|$\\rightarrow$|Word|$\\rightarrow$|Target|\n",
    "|:-:|:-:|:-:|:-:|:-:|\n",
    "|Orange||Juice||1|\n",
    "|Orange||King||0|\n",
    "|Orange||book||0|\n",
    "|Orange||the||0|\n",
    "|Orange||of||0|\n",
    "\n",
    "**Model:**\n",
    "\n",
    "We are going to do the following:\n",
    "\n",
    "$P(y=1|c,t) = \\text{sigmoid}(\\theta_t^Te_c)$\n",
    "\n",
    "#### GloVe Word Vectors\n",
    "\n",
    "The GloVe (global vectors for word representation) algorithm is another way to learn word embeddings.\n",
    "For the following sentence: \"I want a glass of orange juice to go along with my cereal\". We are going to deffine the variable $X_{ij}$\n",
    "\n",
    "$X_{ij}=$ # of times $i$ appears in context of $j$\n",
    "\n",
    "**Model:**\n",
    "\n",
    "- $f(X_{ij})$ is a weighting term to avoid infinity in the logarithm.\n",
    "- $b_i$ equals \"t\"\n",
    "- $b_j$ equals \"c\"\n",
    "\n",
    "minimize $\\sum_{i=1}^{10,000}\\sum_{i=1}^{10,000}f(X_{ij})(\\theta_i^Te_j + b_i + b_j - log(X_{ij}))$\n",
    "\n",
    "### Applications using Word Embeddings\n",
    "#### Sentiment Classification\n",
    "\n",
    "One example of an application of sentiment clasification is business reviews and ratings:\n",
    "\n",
    "<img src='img/img86.jpg' style=\"width:400px; height:180px\"/><br>\n",
    "\n",
    "**Simple sentiment classification model:**\n",
    "\n",
    "For the following sentence: \"The dessert is excellent\". \n",
    "\n",
    "$\\begin{matrix} \n",
    "\\text{The} & O_{4343} & \\rightarrow & E & \\rightarrow & e_{4343} \\\\\n",
    "\\text{dessert} & O_{9665} & \\rightarrow & E & \\rightarrow & e_{9665} \\\\\n",
    "\\text{is} & O_{1} & \\rightarrow & E & \\rightarrow & e_{1} \\\\\n",
    "\\text{excellent} & O_{3852} & \\rightarrow & E & \\rightarrow & e_{3852} \\\\\n",
    "\\end{matrix}$\n",
    "\n",
    "The we are going to average all vectors and pass it to a softmax to determine the rating of the review (1 to 5). \n",
    "One problem of this algorithm is that it ignores words order. For example, in the following sentence this algorithm could fail: \"Completely lacking in good taste, good service and good ambience\"\n",
    "\n",
    "**RNN for setniment classificaition:**\n",
    "\n",
    "We can use a many to one RNN to predict the ratings.\n",
    "\n",
    "<img src='img/img87.jpg' style=\"width:600px; height:325px\"/><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence models and Attention mechanism\n",
    "### Various sequence to sequence architectures\n",
    "#### Basic Models\n",
    "\n",
    "Sequence to sequence models are useful for everything from machine translation to speech recognition. For example, the following sentece: \n",
    "\n",
    "- $\\begin{matrix} \\text{Jane} & \\text{visite} & \\text{l'Afrique} & \\text{en} & \\text{septembre.} \\\\ x^{<1>} & x^{<2>} & x^{<2>} & x^{<4>} & x^{<5>} \\end{matrix}$\n",
    "\n",
    "- $\\begin{matrix} \\text{Jane} & \\text{is} & \\text{visiting} & \\text{Africa} & \\text{in} & \\text{September.} \\\\ y^{<1>} & y^{<2>} & y^{<2>} & y^{<4>} & y^{<5>} & y^{<6>} \\end{matrix}$\n",
    "\n",
    "To solve  this we could use a network like this:\n",
    "\n",
    "<img src='img/img88.jpg' style=\"width:400px; height:150px\"/><br>\n",
    "\n",
    "**Image Captioning**\n",
    "\n",
    "Other application of this is Image Captioning where we have an image and we want to output a caption that represents the image content. For eg. in the following sentence:\n",
    "\n",
    "- $\\begin{matrix} \\text{A} & \\text{Cat} & \\text{sitting} & \\text{on} & \\text{a} & \\text{chair} \\\\ x^{<1>} & x^{<2>} & x^{<2>} & x^{<4>} & x^{<5>} & x^{<6>} \\end{matrix}$\n",
    "\n",
    "<img src='img/img89.jpg' style=\"width:600px; height:225px\"/><br>\n",
    "\n",
    "#### Picking the most likely sentence\n",
    "\n",
    "To determine which is the most accurate translation, we have to find a sentence that maximizes the followint probaility $argmax P( y^{<1>},..., y^{<T_y>}|x)$. The most common algorithm to do this is **Beam Search**\n",
    "\n",
    "**Why not a greedy search?**\n",
    "\n",
    "Greedy search consists in picking the most likely word for each output and feed it to the following instance. The problem with this approach is that the global probability for the entire translation can be higher for low probability predictions at the begging of the sentence, so what we want is to find the maximum global probability for the entire sentence.\n",
    "\n",
    "#### Beam Search\n",
    "\n",
    "In the first step of beam search we run the following network to get the following probability $P(y^{<1>}|x)$. The beam search algorithm has a parameter $B$ called beam width.<br>\n",
    "\n",
    "**Step 1**\n",
    "\n",
    "Choose the \"B\" most probable words in the softmax output.\n",
    "\n",
    "1000 possible outputs >>> $\\begin{bmatrix} \\text{a} \\\\ ... \\\\ \\text{in} \\\\ ... \\\\ \\text{Jane} \\\\ ... \\\\ \\text{September} \\\\ ... \\\\\\text{zulu} \\end{bmatrix}$ \n",
    "\n",
    "**Step 2**\n",
    "\n",
    "Take each chosen \"B\" words, feed it to tha following time step to obtain the probability combination for a next word. $P(y^{<1>},y^{<2>}|x) = P(y^{<1>}|x)P(y^{<2>}| x, y^{<1>})$<br>\n",
    "After this, we choose \"B\" words from all this output and we repeat until we finish the sentence.\n",
    "\n",
    "**NOTE:** If B=1 beam search works in the same way as greedy search.\n",
    "\n",
    "#### Refinements to Beam Search\n",
    "\n",
    "**Length normalization**\n",
    "\n",
    "This algorithm is a small change to the beam search algorithm that can help get better results.\n",
    "\n",
    "$\\text{argmax }\\Pi^{T_y}_{t=1} P(y^{<t>}| x, y^{<1>}, ... , y^{<t-1>})$\n",
    "\n",
    "This formula represents the computed probability for the beam search algorithm. The problem is that we end up with very small numbers and could lose information because of numerical underflow. So to avoid this, we do the following:\n",
    "\n",
    "$\\text{argmax }\\sum^{T_y}_{t=1} log P(y^{<t>}| x, y^{<1>}, ... , y^{<t-1>})$\n",
    "\n",
    "The problem with these formulas is that they prefer short sentences because of multiplying small numbers or adding negative numbers. To solve this we are going to do the following:\n",
    "\n",
    "$\\text{argmax  }\\cfrac{1}{T^\\alpha_y}\\sum^{T_y}_{t=1} log P(y^{<t>}| x, y^{<1>}, ... , y^{<t-1>})$\n",
    "\n",
    "Finally, to choose \"B\" we should take in consideration that the bigger \"B\" is, the more computational cost ther will be.\n",
    "\n",
    "#### Error analysis in beam search\n",
    "\n",
    "Beam search is an approximate search algorithm, also called a heuristic search algorithm so it doesn't always output the most likely sentence. Here we'll learn now to do error analysis in Beam Search.<br>\n",
    "If we have the following sentence:\n",
    "\n",
    "Jane visite l'Afrique en septembre.\n",
    "\n",
    "- Human: Jane visits Africa in September. $y^*$\n",
    "- Algorithm: Jane visited Africa last September. $\\hat{y}$\n",
    "\n",
    "For this:\n",
    "\n",
    "- If $P(y^*|x) > P(\\hat{y}|x)$ then Beam search is at fault.\n",
    "- If $P(y^*|x) \\leq P(\\hat{y}|x)$ then the RNN is at fault.\n",
    "\n",
    "#### Bleu Score\n",
    "\n",
    "One challenge of machine translation is that one sentences could translate to multiple equally good answers. Fot this we are going to apply something called the Bleu (Bilingual Evaluation understudy) Score. For example:\n",
    "\n",
    "French: Le chat est sur le tapis.\n",
    "\n",
    "- Reference 1: The cat is on the mat.<br>\n",
    "- Reference 2: There is a cat on the mat.\n",
    "\n",
    "So as long as the predicted translation gets close to any of the references provided, it will get a high Bleu score. For example if the Machine translation is:\n",
    "\n",
    "- MT Output: the the the the the the the the.\n",
    "\n",
    "- Precision: $\\frac{7}{7}$, meaning that 7 out of 7 words appear in the given reference. Bad metric.\n",
    "- Modified precision: $\\frac{2}{7}$ using each \"the\" in the reference just once.\n",
    "\n",
    "**Bleu score on Unigrams:**\n",
    "\n",
    "$P_1 = \\cfrac{\\sum_{\\text{unigrams} \\in \\hat{y}} \\text{Count}_\\text{Clip}(\\text{Unigram})}{\\sum_{\\text{unigrams} \\in \\hat{y}} \\text{Count}(\\text{Unigram})}$\n",
    "\n",
    "In General:\n",
    "\n",
    "$P_n = \\cfrac{\\sum_{\\text{n-grams} \\in \\hat{y}} \\text{Count}_\\text{Clip}(\\text{n-gram})}{\\sum_{\\text{n-grams} \\in \\hat{y}} \\text{Count}(\\text{n-gram})}$\n",
    "\n",
    "**Bleu Details**\n",
    "\n",
    "$p_n = \\text{Bleu score on n-grams only}$<br>\n",
    "\n",
    "Combined Bleu Score = $\\text{BP} exp(\\frac{1}{4}\\sum^4_{n=1}p_n)$\n",
    "\n",
    "BP = $\\Bigg\\{ \\begin{matrix} \\text{MT_output_length } > \\text{reference_output_length} & 1 \\\\ \\text{otherwise} & exp(1- \\text{reference_output_length / MT_output_length} \\end{matrix}$\n",
    "\n",
    "#### Attention Model\n",
    "\n",
    "The encoder-decoder arquitecture previously seem tends to lower on performance with sentence length. The attention model works looking at parts of sentences at a time to avoid this problem.<br>\n",
    "To avoid this we are going to define a context \"C\" and a parameter \"alpha\" for weighting.\n",
    "\n",
    "<img src='img/img90.jpg' style=\"width:700px; height:350px\"/><br>\n",
    "\n",
    "- $\\alpha^{<t,\\prime{t}>} =$ amount of \"attention\" $y^{<t>}$ should pay to $a^{<\\prime{t}>}$.\n",
    "- $\\sum_{\\prime{t}} \\alpha^{<1,\\prime{t}>} = 1$\n",
    "- $C^{<1>} = \\sum_{\\prime{t}}\\alpha^{<1,\\prime{t}>} a^{<\\prime{t}>}$\n",
    "\n",
    "**Computing attention $\\alpha^{<t,\\prime{t}>}$**\n",
    "\n",
    "$\\alpha^{<t,\\prime{t}>} = \\cfrac{exp(e^{<t,\\prime{t}>})}{\\sum^{T_x}_{\\prime{t}=1}exp(e^{<t,\\prime{t}>})}$\n",
    "\n",
    "To compute $e^{<t,\\prime{t}>}$ we can use a FC layer network.\n",
    "\n",
    "<img src='img/img91.jpg' style=\"width:700px; height:300px\"/><br>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
